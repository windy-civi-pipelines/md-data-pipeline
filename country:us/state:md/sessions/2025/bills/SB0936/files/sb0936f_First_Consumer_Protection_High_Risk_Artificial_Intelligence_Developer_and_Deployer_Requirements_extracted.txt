Title: SENATE BILL 936
Official Title: SENATE BILL 936
Number of Sections: 1
Source: versions - First - Consumer Protection - High-Risk Artificial Intelligence - Developer and Deployer Requirements
Media Type: application/pdf
Strikethrough Detection: 24 sections found

================================================================================

Section 1:
I3, S1 5lr0853
CF 5lr3153
By: Senators Hester, Gile, and Love
Introduced and read first time: January 28, 2025
Assigned to: Finance
A BILL ENTITLED
1 AN ACT concerning
2 Consumer Protection – High–Risk Artificial Intelligence – Developer and
3 Deployer Requirements
4 FOR the purpose of requiring a certain developer of and a certain deployer who uses a
5 certain high–risk artificial intelligence system to use reasonable care to protect
6 consumers from known and reasonably foreseeable risks of certain algorithmic
7 discrimination; prohibiting a developer from providing to a certain deployer or other
8 developer a high–risk artificial intelligence system unless certain disclosures are
9 provided to the deployer or developer; requiring a developer to make certain
10 documentation and information available to complete an impact assessment in a
11 certain manner; requiring a deployer to design, implement, and maintain a risk
12 management policy and program for the high–risk artificial intelligence system in
13 use by the deployer; requiring a deployer to complete an impact assessment of its
14 high–risk artificial intelligence system; requiring a deployer to provide certain
15 information to a consumer regarding the deployment of and decisions made by a
16 high–risk artificial intelligence system; requiring a deployer to provide consumers
17 with an opportunity to correct certain information and appeal a certain
18 consequential decision; authorizing the Attorney General to enforce this Act;
19 authorizing a consumer to bring a civil action against a deployer under certain
20 circumstances; and generally relating to the use of high–risk artificial intelligence
21 systems in the State.
22 BY adding to
23 Article – Commercial Law
24 Section 14–47A–01 through 14–47A–08 to be under the new subtitle “Subtitle 47A.
25 High–Risk Artificial Intelligence Developer Act”
26 Annotated Code of Maryland
27 (2013 Replacement Volume and 2024 Supplement)
28 SECTION 1. BE IT ENACTED BY THE GENERAL ASSEMBLY OF MARYLAND,
29 That the Laws of Maryland read as follows:
EXPLANATION: CAPITALS INDICATE MATTER ADDED TO EXISTING LAW.
[Brackets] indicate matter deleted from exist in g l aw . *sb0936*
2 SENATE BILL 936
1 Article – Commercial Law
2 SUBTITLE 47A. HIGH–RISK ARTIFICIAL INTELLIGENCE DEVELOPER ACT.
3 14–47A–01.
4 (A) IN THIS SUBTITLE THE FOLLOWING WORDS HAVE THE MEANINGS
5 INDICATED.
6 (B) (1) “ALGORITHMIC DISCRIMINATION” MEANS THE USE OF AN
7 ARTIFICIAL INTELLIGENCE SYSTEM THAT RESULTS IN AN UNLAWFUL DIFFERENTIAL
8 TREATMENT OR IMPACT THAT DISFAVORS AN INDIVIDUAL OR GROUP OF
9 INDIVIDUALS ON THE BASIS OF THE INDIVIDUAL’S OR GROUP’S ACTUAL OR
10 PERCEIVED:
11 (I) AGE;
12 (II) COLOR;
13 (III) DISABILITY;
14 (IV) ETHNICITY;
15 (V) GENETIC INFORMATION;
16 (VI) LIMITED PROFICIENCY IN THE ENGLISH LANGUAGE;
17 (VII) NATIONAL ORIGIN;
18 (VIII) RACE;
19 (IX) RELIGION;
20 (X) REPRODUCTIVE HEALTH;
21 (XI) SEX;
22 (XII) SEXUAL ORIENTATION;
23 (XIII) VETERAN STATUS; OR
24 (XIV) CLASSIFICATION OTHERWISE PROTECTED UNDER STATE
25 OR FEDERAL LAW.
SENATE BILL 936 3
1 (2) “ALGORITHMIC DISCRIMINATION” DOES NOT INCLUDE:
2 (I) THE OFFER, LICENSE, OR USE OF A HIGH–RISK ARTIFICIAL
3 INTELLIGENCE SYSTEM BY A DEVELOPER OR DEPLOYER FOR THE SOLE PURPOSE OF
4 THE DEVELOPER’S OR DEPLOYER’S SELF–TESTING TO IDENTIFY, MITIGATE, OR
5 PREVENT DISCRIMINATION OR OTHERWISE ENSURE COMPLIANCE WITH STATE AND
6 FEDERAL LAW;
7 (II) THE EXPANSION OF AN APPLICANT, A CUSTOMER, OR A
8 PARTICIPANT POOL TO INCREASE DIVERSITY OR REDRESS HISTORICAL
9 DISCRIMINATION; OR
10 (III) AN ACT OR OMISSION BY OR ON BEHALF OF A PRIVATE CLUB
11 OR OTHER ESTABLISHMENT NOT IN FACT OPEN TO THE PUBLIC, AS PROVIDED BY
12 TITLE II OF THE CIVIL RIGHTS ACT OF 1964 UNDER 42 U.S.C. § 2000A(E).
13 (C) (1) “ARTIFICIAL INTELLIGENCE SYSTEM” MEANS A MACHINE
14 LEARNING–BASED SYSTEM THAT FOR ANY EXPLICIT OR IMPLICIT OBJECTIVE,
15 INFERS FROM THE INPUTS THE SYSTEM RECEIVES HOW TO GENERATE OUTPUTS,
16 INCLUDING CONTENT, DECISIONS, PREDICTIONS, OR RECOMMENDATIONS THAT CAN
17 INFLUENCE PHYSICAL OR VIRTUAL ENVIRONMENTS.
18 (2) “ARTIFICIAL INTELLIGENCE SYSTEM” DOES NOT INCLUDE AN
19 ARTIFICIAL INTELLIGENCE SYSTEM OR A MODEL THAT IS USED FOR DEVELOPMENT,
20 PROTOTYPING, AND RESEARCH ACTIVITIES BEFORE THE ARTIFICIAL INTELLIGENCE
21 SYSTEM OR MODEL IS RELEASED ON THE MARKET.
22 (D) “CONSEQUENTIAL DECISION” MEANS A DECISION THAT HAS A
23 MATERIALLY LEGAL OR SIMILARLY SIGNIFICANT EFFECT ON THE PROVISION OR
24 DENIAL TO A CONSUMER OF:
25 (1) PAROLE, PROBATION, A PARDON, OR ANY OTHER RELEASE FROM
26 INCARCERATION OR COURT SUPERVISION;
27 (2) EDUCATION ENROLLMENT OR EDUCATION OPPORTUNITY;
28 (3) ACCESS TO OR PROVISION OF EMPLOYMENT;
29 (4) FINANCIAL OR LENDING SERVICES;
30 (5) ACCESS TO OR THE PROVISION OF HEALTH CARE SERVICES;
4 SENATE BILL 936
1 (6) HOUSING;
2 (7) INSURANCE;
3 (8) MARITAL STATUS; OR
4 (9) LEGAL SERVICE.
5 (E) (1) “CONSUMER” MEANS AN INDIVIDUAL WHO IS A RESIDENT OF THE
6 STATE AND IS ACTING ONLY IN A PERSONAL OR HOUSEHOLD CONTEXT.
7 (2) “CONSUMER” DOES NOT INCLUDE AN INDIVIDUAL ACTING IN A
8 COMMERCIAL OR EMPLOYMENT CONTEXT.
9 (F) “DEPLOYER” MEANS A PERSON DOING BUSINESS IN THE STATE THAT
10 DEPLOYS OR USES A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM TO MAKE A
11 CONSEQUENTIAL DECISION IN THE STATE.
12 (G) “DEVELOPER” MEANS A PERSON DOING BUSINESS IN THE STATE THAT
13 DEVELOPS OR INTENTIONALLY AND SUBSTANTIALLY MODIFIES A HIGH–RISK
14 ARTIFICIAL INTELLIGENCE SYSTEM THAT IS OFFERED, SOLD, LEASED, GIVEN, OR
15 OTHERWISE PROVIDED TO CONSUMERS IN THE STATE.
16 (H) (1) “GENERAL–PURPOSE ARTIFICIAL INTELLIGENCE MODEL” MEANS
17 A MODEL USED BY AN ARTIFICIAL INTELLIGENCE SYSTEM THAT:
18 (I) DISPLAYS SIGNIFICANT GENERALITY;
19 (II) IS CAPABLE OF COMPETENTLY PERFORMING A WIDE RANGE
20 OF DISTINCT TASKS; AND
21 (III) CAN BE INTEGRATED INTO A VARIETY OF DOWNSTREAM
22 APPLICATIONS OR SYSTEMS.
23 (2) “GENERAL–PURPOSE ARTIFICIAL INTELLIGENCE MODEL” DOES
24 NOT INCLUDE AN ARTIFICIAL INTELLIGENCE MODEL THAT IS USED FOR
25 DEVELOPMENT, PROTOTYPING, AND RESEARCH ACTIVITIES BEFORE THE
26 ARTIFICIAL INTELLIGENCE MODEL IS RELEASED ON THE MARKET.
27 (I) “GENERATIVE ARTIFICIAL INTELLIGENCE” MEANS ARTIFICIAL
28 INTELLIGENCE THAT IS CAPABLE OF AND USED TO PRODUCE SYNTHETIC CONTENT,
29 INCLUDING AUDIO, IMAGES, TEXT, AND VIDEOS.
SENATE BILL 936 5
1 (J) “GENERATIVE ARTIFICIAL INTELLIGENCE SYSTEM” MEANS ANY
2 ARTIFICIAL INTELLIGENCE SYSTEM OR SERVICE THAT INCORPORATES GENERATIVE
3 ARTIFICIAL INTELLIGENCE.
4 (K) (1) “HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM” MEANS AN
5 ARTIFICIAL INTELLIGENCE SYSTEM THAT IS SPECIFICALLY INTENDED TO
6 AUTONOMOUSLY MAKE, OR BE A SUBSTANTIAL FACTOR IN MAKING, A
7 CONSEQUENTIAL DECISION.
8 (2) “HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM” DOES NOT
9 INCLUDE:
10 (I) AN ARTIFICIAL INTELLIGENCE SYSTEM THAT IS INTENDED
11 TO:
12 1. PERFORM A NARROW PROCEDURAL TASK;
13 2. IMPROVE THE RESULT OF A PREVIOUSLY COMPLETED
14 HUMAN ACTIVITY;
15 3. DETECT ANY DECISION–MAKING PATTERNS OR ANY
16 DEVIATIONS FROM PREEXISTING DECISION–MAKING PATTERNS; OR
17 4. PERFORM A PREPARATORY TASK TO AN ASSESSMENT
18 RELEVANT TO A CONSEQUENTIAL DECISION; OR
19 (II) THE FOLLOWING TECHNOLOGIES:
20 1. ANTIFRAUD TECHNOLOGY THAT DOES NOT USE
21 FACIAL RECOGNITION TECHNOLOGY;
22 2. ARTIFICIAL INTELLIGENCE–ENABLED VIDEO GAME
23 TECHNOLOGY;
24 3. ANTIMALWARE AND ANTIVIRUS TECHNOLOGY;
25 4. AUTONOMOUS VEHICLE TECHNOLOGY;
26 5. CALCULATORS;
27 6. CYBERSECURITY TECHNOLOGY;
28 7. DATABASES AND DATA STORAGE;
6 SENATE BILL 936
1 8. FIREWALL TECHNOLOGY;
2 9. INTERNET DOMAIN REGISTRATION;
3 10. INTERNET WEBSITE LOADING;
4 11. NETWORKING;
5 12. SPAM AND ROBOCALL FILTERING;
6 13. SPELLCHECKING TECHNOLOGY;
7 14. SPREADSHEETS;
8 15. WEB CACHING;
9 16. WEB HOSTING OR SIMILAR TECHNOLOGY; OR
10 17. TECHNOLOGY THAT COMMUNICATES WITH
11 CONSUMERS IN NATURAL LANGUAGE FOR THE PURPOSE OF PROVIDING USERS WITH
12 INFORMATION, MAKING REFERRALS OR RECOMMENDATIONS, AND ANSWERING
13 QUESTIONS AND IS SUBJECT TO AN ACCEPTABLE USE POLICY THAT PROHIBITS
14 GENERATING CONTENT THAT IS DISCRIMINATORY OR UNLAWFUL.
15 (L) (1) “INTENTIONAL AND SUBSTANTIAL MODIFICATION” MEANS A
16 DELIBERATE CHANGE MADE TO:
17 (I) AN ARTIFICIAL INTELLIGENCE SYSTEM THAT RESULTS IN A
18 NEW MATERIAL RISK OF ALGORITHMIC DISCRIMINATION; OR
19 (II) A GENERAL–PURPOSE ARTIFICIAL INTELLIGENCE MODEL
20 THAT:
21 1. AFFECTS COMPLIANCE OF THE GENERAL–PURPOSE
22 ARTIFICIAL INTELLIGENCE MODEL;
23 2. MATERIALLY CHANGES THE PURPOSE OF THE
24 GENERAL–PURPOSE ARTIFICIAL INTELLIGENCE MODEL; OR
25 3. RESULTS IN ANY NEW REASONABLY FORESEEABLE
26 RISK OF ALGORITHMIC DISCRIMINATION.
SENATE BILL 936 7
1 (2) “INTENTIONAL AND SUBSTANTIAL MODIFICATION” DOES NOT
2 INCLUDE A CHANGE MADE TO A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, OR
3 THE PERFORMANCE OF A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, IF:
4 (I) THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM
5 CONTINUES TO LEARN AFTER THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM IS
6 DEPLOYED OR OFFERED, SOLD, LEASED, LICENSED, GIVEN, OR OTHERWISE MADE
7 AVAILABLE TO A DEPLOYER; AND
8 (II) THE CHANGE:
9 1. IS MADE TO THE HIGH–RISK ARTIFICIAL
10 INTELLIGENCE SYSTEM AS A RESULT OF ANY LEARNING DESCRIBED IN ITEM (I) OF
11 THIS PARAGRAPH;
12 2. WAS PREDETERMINED BY THE DEPLOYER OR THE
13 THIRD PARTY CONTRACTED BY THE DEPLOYER; AND
14 3. INCLUDED AND CONCLUDED WITHIN THE INITIAL
15 IMPACT ASSESSMENT OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM
16 UNDER § 14–47A–04(C) OF THIS SUBTITLE.
17 (M) (1) “PERSON” MEANS AN INDIVIDUAL, AN ASSOCIATION, A
18 COOPERATIVE, A CORPORATION, A LIMITED LIABILITY COMPANY, A PARTNERSHIP,
19 A TRUST, A JOINT VENTURE, OR ANY OTHER LEGAL OR COMMERCIAL ENTITY AND
20 ANY SUCCESSOR, REPRESENTATIVE, AGENCY, OR INSTRUMENTALITY THEREOF.
21 (2) “PERSON” DOES NOT INCLUDE A GOVERNMENTAL UNIT.
22 (N) “PRINCIPAL BASIS” MEANS THE USE OF AN OUTPUT OF A HIGH–RISK
23 ARTIFICIAL INTELLIGENCE SYSTEM TO MAKE A DECISION WITHOUT:
24 (1) HUMAN REVIEW, OVERSIGHT, INVOLVEMENT, OR INTERVENTION;
25 OR
26 (2) MEANINGFUL CONSIDERATION BY A HUMAN.
27 (O) (1) “SUBSTANTIAL FACTOR” MEANS A FACTOR GENERATED BY AN
28 ARTIFICIAL INTELLIGENCE SYSTEM THAT IS:
29 (I) THE PRINCIPAL BASIS FOR MAKING A CONSEQUENTIAL
30 DECISION; OR
8 SENATE BILL 936
1 (II) CAPABLE OF ALTERING THE OUTCOME OF A
2 CONSEQUENTIAL DECISION.
3 (2) “SUBSTANTIAL FACTOR” INCLUDES ANY USE OF AN ARTIFICIAL
4 INTELLIGENCE SYSTEM TO GENERATE ANY CONTENT, DECISION, PREDICTION, OR
5 RECOMMENDATION CONCERNING A CONSUMER THAT IS USED AS THE PRINCIPAL
6 BASIS TO MAKE A CONSEQUENTIAL DECISION CONCERNING THE CONSUMER.
7 (P) “SYNTHETIC CONTENT” MEANS INFORMATION, SUCH AS AUDIO CLIPS,
8 IMAGES, TEXT, AND VIDEO, THAT IS PRODUCED OR SIGNIFICANTLY MODIFIED OR
9 GENERATED BY ALGORITHMS, INCLUDING BY AN ARTIFICIAL INTELLIGENCE
10 SYSTEM.
11 14–47A–02.
12 THIS SUBTITLE DOES NOT APPLY TO:
13 (1) EXCEPT IN A SITUATION WHERE A HIGH–RISK ARTIFICIAL
14 INTELLIGENCE SYSTEM IS USED TO MAKE, OR IS A SUBSTANTIAL FACTOR IN MAKING,
15 A DECISION CONCERNING EMPLOYMENT OR HOUSING, A DEVELOPER OR DEPLOYER
16 THAT USES AN ARTIFICIAL INTELLIGENCE SYSTEM ACQUIRED BY OR FOR THE
17 FEDERAL GOVERNMENT OR ANY FEDERAL AGENCY OR DEPARTMENT, INCLUDING:
18 (I) THE U.S. DEPARTMENT OF COMMERCE;
19 (II) THE U.S. DEPARTMENT OF DEFENSE; AND
20 (III) THE NATIONAL AERONAUTICS AND SPACE
21 ADMINISTRATION;
22 (2) AN INSURER, OR A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM
23 DEVELOPED OR DEPLOYED BY AN INSURER FOR USE IN THE BUSINESS OF
24 INSURANCE, IF THE INSURER IS REGULATED AND SUPERVISED BY THE INSURANCE
25 ADMINISTRATION AND SUBJECT TO THE PROVISIONS UNDER TITLE 13 OF THIS
26 ARTICLE; OR
27 (3) A DEVELOPER, A DEPLOYER, OR ANY OTHER PERSON WHO:
28 (I) IS A COVERED ENTITY UNDER THE FEDERAL HEALTH
29 INSURANCE PORTABILITY AND ACCOUNTABILITY ACT OF 1996 UNDER 42 U.S.C. §
30 1320D THROUGH 1320D–9, AND THE CORRESPONDING FEDERAL REGULATIONS;
31 AND
SENATE BILL 936 9
1 (II) PROVIDES:
2 1. HEALTH CARE RECOMMENDATIONS GENERATED BY
3 AN ARTIFICIAL INTELLIGENCE SYSTEM IN WHICH A HEALTH CARE PROVIDER IS
4 REQUIRED TO TAKE ACTION TO IMPLEMENT THE HEALTH CARE
5 RECOMMENDATIONS; OR
6 2. SERVICES USING AN ARTIFICIAL INTELLIGENCE
7 SYSTEM FOR AN ADMINISTRATIVE, FINANCIAL, QUALITY MEASUREMENT, SECURITY,
8 OR PERFORMANCE IMPROVEMENT FUNCTION.
9 14–47A–03.
10 (A) (1) BEGINNING FEBRUARY 1, 2026, A DEVELOPER OF A
11 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM SHALL USE REASONABLE CARE TO
12 PROTECT CONSUMERS FROM ANY KNOWN OR REASONABLY FORESEEABLE RISKS OF
13 ALGORITHMIC DISCRIMINATION.
14 (2) IN AN ENFORCEMENT ACTION BROUGHT BY THE ATTORNEY
15 GENERAL UNDER THIS SUBTITLE, THERE SHALL BE A REBUTTABLE PRESUMPTION
16 THAT A DEVELOPER USED REASONABLE CARE AS REQUIRED UNDER THIS
17 SUBSECTION IF THE DEVELOPER COMPLIED WITH THE PROVISIONS OF THIS
18 SECTION.
19 (B) BEGINNING FEBRUARY 1, 2026, AND SUBJECT TO SUBSECTION (D) OF
20 THIS SECTION, A DEVELOPER OF A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM
21 MAY NOT OFFER, SELL, LEASE, GIVE, OR OTHERWISE PROVIDE TO A DEPLOYER, OR
22 OTHER DEVELOPER, A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, UNLESS THE
23 DEVELOPER MAKES AVAILABLE TO THE DEPLOYER OR OTHER DEVELOPER:
24 (1) A STATEMENT DISCLOSING THE INTENDED USES OF THE
25 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM;
26 (2) DOCUMENTATION DISCLOSING:
27 (I) THE KNOWN OR REASONABLY FORESEEABLE LIMITATIONS
28 OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, INCLUDING THE KNOWN OR
29 REASONABLY FORESEEABLE RISKS OF ALGORITHMIC DISCRIMINATION ARISING
30 FROM THE INTENDED USES OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM;
31 (II) THE PURPOSE OF THE HIGH–RISK ARTIFICIAL
32 INTELLIGENCE SYSTEM AND THE INTENDED BENEFITS AND USES OF THE HIGH–RISK
33 ARTIFICIAL INTELLIGENCE SYSTEM;
10 SENATE BILL 936
1 (III) A SUMMARY DESCRIBING THE MANNER IN WHICH THE
2 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM WAS EVALUATED FOR
3 PERFORMANCE BEFORE THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM WAS
4 LICENSED, SOLD, LEASED, GIVEN, OR OTHERWISE MADE AVAILABLE TO A DEPLOYER;
5 (IV) THE MEASURES THE DEVELOPER HAS TAKEN TO MITIGATE
6 REASONABLY FORESEEABLE RISKS OF ALGORITHMIC DISCRIMINATION THAT THE
7 DEVELOPER KNOWS ARISES FROM DEPLOYMENT OR USE OF THE HIGH–RISK
8 ARTIFICIAL INTELLIGENCE SYSTEM; AND
9 (V) THE MANNER IN WHICH AN INDIVIDUAL CAN USE THE
10 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM AND MONITOR THE PERFORMANCE
11 OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM FOR RISK OF ALGORITHMIC
12 DISCRIMINATION;
13 (3) DOCUMENTATION DESCRIBING:
14 (I) THE MANNER IN WHICH THE HIGH–RISK ARTIFICIAL
15 INTELLIGENCE SYSTEM WAS EVALUATED FOR PERFORMANCE, AND MITIGATION OF
16 ALGORITHMIC DISCRIMINATION BEFORE THE HIGH–RISK ARTIFICIAL
17 INTELLIGENCE SYSTEM WAS OFFERED, SOLD, LEASED, LICENSED, GIVEN, OR
18 OTHERWISE MADE AVAILABLE TO THE DEPLOYER OR OTHER DEVELOPER;
19 (II) A HIGH–LEVEL SUMMARY OF THE MANNER IN WHICH DATA
20 SOURCES WERE EVALUATED FOR POTENTIAL BIAS AND APPROPRIATE MITIGATIONS
21 WERE APPLIED;
22 (III) THE INTENDED OUTPUTS OF THE HIGH–RISK ARTIFICIAL
23 INTELLIGENCE SYSTEM;
24 (IV) THE MEASURES THE DEVELOPER HAS TAKEN TO MITIGATE
25 ANY KNOWN OR REASONABLY FORESEEABLE RISKS OF ALGORITHMIC
26 DISCRIMINATION THAT MAY ARISE FROM REASONABLY FORESEEABLE DEPLOYMENT
27 OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM; AND
28 (V) THE MANNER IN WHICH THE HIGH–RISK ARTIFICIAL
29 INTELLIGENCE SYSTEM SHOULD BE USED, NOT USED, AND MONITORED BY AN
30 INDIVIDUAL WHEN BEING USED; AND
31 (4) ANY ADDITIONAL DOCUMENTATION THAT IS REASONABLY
32 NECESSARY TO ASSIST A DEPLOYER TO:
SENATE BILL 936 11
1 (I) UNDERSTAND THE OUTPUTS OF THE HIGH–RISK
2 ARTIFICIAL INTELLIGENCE SYSTEM; AND
3 (II) MONITOR THE PERFORMANCE OF THE HIGH–RISK
4 ARTIFICIAL INTELLIGENCE SYSTEM FOR RISKS OF ALGORITHMIC DISCRIMINATION.
5 (C) (1) SUBJECT TO SUBSECTION (D) OF THIS SECTION, A DEVELOPER
6 THAT, ON OR AFTER FEBRUARY 1, 2026, OFFERS, SELLS, LEASES, LICENSES, GIVES,
7 OR OTHERWISE MAKES AVAILABLE TO A DEPLOYER OR OTHER DEVELOPER A
8 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, TO THE EXTENT PRACTICABLE,
9 SHALL MAKE AVAILABLE TO DEPLOYERS AND OTHER DEVELOPERS THE
10 DOCUMENTATION AND INFORMATION NECESSARY FOR A DEPLOYER OR THIRD
11 PARTY CONTRACTED BY A DEPLOYER TO COMPLETE AN IMPACT ASSESSMENT
12 UNDER § 14–47A–04(C) OF THIS SUBTITLE.
13 (2) THE DEVELOPER SHALL MAKE DOCUMENTATION AND
14 INFORMATION AVAILABLE AS REQUIRED UNDER PARAGRAPH (1) OF THIS
15 SUBSECTION THROUGH:
16 (I) ARTIFACTS, INCLUDING MODEL CARD FILES THAT
17 ACCOMPANY THE MODEL AND PROVIDE INFORMATION ABOUT DISCOVERABILITY,
18 REPRODUCIBILITY, AND SHARING;
19 (II) DATASET CARD FILES THAT:
20 1. ARE USED TO INFORM USERS ABOUT HOW TO
21 RESPONSIBLY USE THE DATA IN A DATASET; AND
22 2. CONTAIN INFORMATION ABOUT POTENTIAL BIASES
23 OF THE DATA; OR
24 (III) OTHER IMPACT ASSESSMENTS.
25 (D) (1) FOR ANY DISCLOSURE REQUIRED UNDER THIS SECTION, A
26 DEVELOPER, NOT LATER THAN 90 DAYS AFTER THE DEVELOPER PERFORMS AN
27 INTENTIONAL AND SUBSTANTIAL MODIFICATION TO A HIGH–RISK ARTIFICIAL
28 INTELLIGENCE SYSTEM, SHALL UPDATE THE DISCLOSURE TO ENSURE ACCURACY.
29 (2) A DEVELOPER THAT ALSO SERVES AS A DEPLOYER FOR ANY
30 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM IS NOT REQUIRED TO GENERATE
31 THE DOCUMENTATION REQUIRED UNDER THIS SECTION UNLESS THE HIGH–RISK
32 ARTIFICIAL INTELLIGENCE SYSTEM IS PROVIDED TO AN UNAFFILIATED ENTITY
33 ACTING AS A DEPLOYER OR AS OTHERWISE REQUIRED BY LAW.
12 SENATE BILL 936
1 (E) A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM SHALL BE PRESUMED
2 TO SATISFY THE APPLICABLE REQUIREMENTS UNDER THIS SECTION AND ANY
3 REGULATIONS ADOPTED IN ACCORDANCE WITH THIS SUBTITLE IF THE HIGH–RISK
4 ARTIFICIAL INTELLIGENCE SYSTEM IS IN CONFORMITY WITH THE LATEST VERSION
5 OF:
6 (1) THE ARTIFICIAL INTELLIGENCE RISK MANAGEMENT
7 FRAMEWORK PUBLISHED BY THE NATIONAL INSTITUTE OF STANDARDS AND
8 TECHNOLOGY;
9 (2) STANDARD ISO/IEC 42001 OF THE INTERNATIONAL
10 ORGANIZATION FOR STANDARDIZATION; OR
11 (3) ANOTHER NATIONALLY OR INTERNATIONALLY RECOGNIZED RISK
12 MANAGEMENT FRAMEWORK FOR ARTIFICIAL INTELLIGENCE SYSTEMS THAT IS
13 SUBSTANTIALLY EQUIVALENT TO, AND AT LEAST AS STRINGENT AS, THE
14 REQUIREMENTS ESTABLISHED UNDER THIS SECTION.
15 (F) THIS SECTION MAY NOT BE CONSTRUED TO REQUIRE A DEVELOPER TO
16 DISCLOSE ANY INFORMATION:
17 (1) THAT IS A TRADE SECRET, AS DEFINED IN § 11–1201 OF THIS
18 ARTICLE, OR OTHERWISE PROTECTED FROM DISCLOSURE UNDER STATE OR
19 FEDERAL LAW; OR
20 (2) THE DISCLOSURE OF WHICH WOULD:
21 (I) PRESENT A SECURITY RISK TO THE DEVELOPER; OR
22 (II) REQUIRE THE DEVELOPER TO DISCLOSE CONFIDENTIAL OR
23 PROPRIETARY INFORMATION.
24 (G) (1) EACH DEVELOPER OF A GENERATIVE ARTIFICIAL INTELLIGENCE
25 SYSTEM THAT GENERATES OR MODIFIES SYNTHETIC CONTENT SHALL ENSURE THAT
26 THE OUTPUTS OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM:
27 (I) ARE MARKED AT THE TIME THE OUTPUT IS GENERATED AND
28 IN A MANNER THAT IS DETECTABLE BY CONSUMERS; AND
29 (II) COMPLY WITH ANY ACCESSIBILITY REQUIREMENTS.
SENATE BILL 936 13
1 (2) FOR SYNTHETIC CONTENT THAT IS AN AUDIO, IMAGE, OR VIDEO
2 FORMED AS PART OF AN ARTISTIC, CREATIVE, SATIRICAL, FICTIONAL ANALOGOUS
3 WORK OR PROGRAM, A MARKING OF HIGH–RISK ARTIFICIAL INTELLIGENCE
4 SYSTEMS UNDER PARAGRAPH (1) OF THIS SUBSECTION SHALL BE LIMITED IN A
5 MANNER NOT TO HINDER THE DISPLAY OR ENJOYMENT OF THE WORK OR PROGRAM.
6 (3) THE MARKING OF OUTPUTS REQUIRED UNDER PARAGRAPH (1) OF
7 THIS SUBSECTION DOES NOT APPLY TO:
8 (I) SYNTHETIC CONTENT THAT:
9 1. CONSISTS EXCLUSIVELY OF TEXT;
10 2. IS PUBLISHED TO INFORM THE PUBLIC ON ANY
11 MATTER OF PUBLIC INTEREST; OR
12 3. IS UNLIKELY TO MISLEAD A REASONABLE PERSON
13 CONSUMING THE SYNTHETIC CONTENT; OR
14 (II) THE OUTPUTS OF A HIGH–RISK ARTIFICIAL INTELLIGENCE
15 SYSTEM THAT:
16 1. PERFORMS AN ASSISTIVE FUNCTION FOR STANDARD
17 EDITING;
18 2. DOES NOT SUBSTANTIALLY ALTER THE INPUT DATA
19 PROVIDED BY THE DEVELOPER, OR IS USED TO DETECT, PREVENT, OR INVESTIGATE;
20 OR
21 3. PROSECUTES A CRIME AS AUTHORIZED BY LAW.
22 14–47A–04.
23 (A) (1) BEGINNING FEBRUARY 1, 2026, EACH DEPLOYER SHALL USE
24 REASONABLE CARE TO PROTECT CONSUMERS FROM ANY KNOWN OR REASONABLY
25 FORESEEABLE RISKS OF ALGORITHMIC DISCRIMINATION.
26 (2) IN AN ENFORCEMENT ACTION BROUGHT BY THE ATTORNEY
27 GENERAL UNDER THIS SUBTITLE, THERE SHALL BE A REBUTTABLE PRESUMPTION
28 THAT A DEPLOYER USED REASONABLE CARE AS REQUIRED UNDER THIS
29 SUBSECTION IF THE DEPLOYER COMPLIED WITH THE REQUIREMENTS OF THIS
30 SECTION.
14 SENATE BILL 936
1 (B) (1) BEGINNING FEBRUARY 1, 2026, AND SUBJECT TO PARAGRAPH (2)
2 OF THIS SUBSECTION, A DEPLOYER OF A HIGH–RISK ARTIFICIAL INTELLIGENCE
3 SYSTEM SHALL DESIGN, IMPLEMENT, AND MAINTAIN A RISK MANAGEMENT POLICY
4 AND PROGRAM FOR THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM.
5 (2) EACH RISK MANAGEMENT POLICY DESIGNED, IMPLEMENTED,
6 AND MAINTAINED IN ACCORDANCE WITH PARAGRAPH (1) OF THIS SUBSECTION
7 SHALL:
8 (I) SPECIFY THE PRINCIPLES, PROCESSES, AND PERSONNEL
9 THAT THE DEPLOYER USES TO IDENTIFY, MITIGATE, AND DOCUMENT ANY RISK OF
10 ALGORITHMIC DISCRIMINATION THAT IS A REASONABLY FORESEEABLE
11 CONSEQUENCE OF DEPLOYING OR USING THE HIGH–RISK ARTIFICIAL
12 INTELLIGENCE SYSTEM;
13 (II) BE REGULARLY REVIEWED AND UPDATED OVER THE LIFE
14 CYCLE OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM; AND
15 (III) BE REASONABLE AND IN CONSIDERATION OF THE
16 GUIDANCE AND STANDARDS PROVIDED IN THE LATEST VERSION OF:
17 1. THE ARTIFICIAL INTELLIGENCE RISK MANAGEMENT
18 FRAMEWORK PUBLISHED BY THE NATIONAL INSTITUTE OF STANDARDS AND
19 TECHNOLOGY;
20 2. STANDARD ISO/IEC 42001 OF THE INTERNATIONAL
21 ORGANIZATION FOR STANDARDIZATION;
22 3. ANOTHER NATIONALLY OR INTERNATIONALLY
23 RECOGNIZED RISK MANAGEMENT FRAMEWORK FOR ARTIFICIAL INTELLIGENCE
24 SYSTEMS WITH REQUIREMENTS THAT ARE SUBSTANTIALLY EQUIVALENT TO, AND AT
25 LEAST AS STRINGENT AS, THE REQUIREMENTS ESTABLISHED UNDER THIS SECTION;
26 OR
27 4. ANY RISK MANAGEMENT FRAMEWORK FOR
28 ARTIFICIAL INTELLIGENCE SYSTEMS THAT THE ATTORNEY GENERAL MAY
29 DESIGNATE AND IS SUBSTANTIALLY EQUIVALENT TO, AND AT LEAST AS STRINGENT
30 AS, THE GUIDANCE AND STANDARDS OF THE FRAMEWORK DESCRIBED IN ITEM 1 OF
31 THIS ITEM.
32 (3) A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM SHALL BE
33 PRESUMED TO SATISFY THE REQUIREMENTS UNDER THIS SECTION AND ANY
34 REGULATIONS ADOPTED IN ACCORDANCE WITH THIS SUBTITLE IF THE HIGH–RISK
SENATE BILL 936 15
1 ARTIFICIAL INTELLIGENCE SYSTEM IS IN CONFORMITY WITH THE LATEST VERSION
2 OF:
3 (I) THE ARTIFICIAL INTELLIGENCE RISK MANAGEMENT
4 FRAMEWORK PUBLISHED BY THE NATIONAL INSTITUTE OF STANDARDS AND
5 TECHNOLOGY;
6 (II) STANDARD ISO/IEC 42001 OF THE INTERNATIONAL
7 ORGANIZATION FOR STANDARDIZATION; OR
8 (III) ANOTHER NATIONALLY OR INTERNATIONALLY
9 RECOGNIZED RISK MANAGEMENT FRAMEWORK FOR ARTIFICIAL INTELLIGENCE
10 SYSTEMS THAT ARE SUBSTANTIALLY EQUIVALENT TO, AND AT LEAST AS STRINGENT
11 AS, THE REQUIREMENTS ESTABLISHED UNDER THIS SECTION.
12 (C) (1) SUBJECT TO PARAGRAPHS (2) AND (3) OF THIS SUBSECTION AND
13 EXCEPT AS PROVIDED IN PARAGRAPH (4) OF THIS SUBSECTION:
14 (I) ON OR AFTER FEBRUARY 1, 2026, BEFORE INITIAL
15 DEPLOYMENT OF A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM OR USE OF A
16 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, A DEPLOYER SHALL COMPLETE AN
17 IMPACT ASSESSMENT OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM; AND
18 (II) AT LEAST 90 DAYS BEFORE A SIGNIFICANT UPDATE TO A
19 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM IS MADE AVAILABLE, A DEPLOYER
20 SHALL COMPLETE AN IMPACT ASSESSMENT OF THE HIGH–RISK ARTIFICIAL
21 INTELLIGENCE SYSTEM IF THE UPDATE PRODUCES A NEW VERSION OR RELEASE OR
22 SIMILAR CHANGE TO THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM THAT:
23 1. INTRODUCES SIGNIFICANT CHANGES TO THE USE
24 CASE OR KEY FUNCTIONALITY OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE
25 SYSTEM; AND
26 2. RESULTS IN A NEW OR REASONABLY FORESEEABLE
27 RISK OF ALGORITHMIC DISCRIMINATION.
28 (2) EACH IMPACT ASSESSMENT COMPLETED UNDER PARAGRAPH (1)
29 OF THIS SUBSECTION SHALL INCLUDE:
30 (I) A STATEMENT BY THE DEPLOYER DISCLOSING THE
31 PURPOSE AND INTENDED USE CASES AND DEPLOYMENT CONTEXT OF, AND BENEFITS
32 AFFORDED BY, THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM;
16 SENATE BILL 936
1 (II) AN ANALYSIS OF WHETHER THE DEPLOYMENT OF THE
2 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM:
3 1. POSES ANY KNOWN OR REASONABLY FORESEEABLE
4 RISKS OF ALGORITHMIC DISCRIMINATION;
5 2. THE NATURE OF ANY ALGORITHMIC
6 DISCRIMINATION; AND
7 3. THE STEPS THAT HAVE BEEN TAKEN TO MITIGATE
8 RISKS;
9 (III) FOR A POSTDEPLOYMENT IMPACT ASSESSMENT
10 COMPLETED UNDER THIS SUBSECTION, AN ANALYSIS OF WHETHER THE INTENDED
11 USE CASES OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, AS UPDATED,
12 WERE CONSISTENT WITH, OR VARIED FROM, THE DEVELOPER’S INTENDED USES OF
13 THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM;
14 (IV) A DESCRIPTION OF THE CATEGORIES OF DATA THE
15 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM PROCESSES AS INPUTS AND THE
16 OUTPUTS THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM PRODUCES;
17 (V) IF THE DEPLOYER USED DATA TO CUSTOMIZE THE
18 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, AN OVERVIEW OF THE CATEGORIES
19 OF DATA THE DEPLOYER USED TO CUSTOMIZE THE HIGH–RISK ARTIFICIAL
20 INTELLIGENCE SYSTEM;
21 (VI) A LIST OF METRICS USED TO EVALUATE THE PERFORMANCE
22 AND KNOWN LIMITATIONS OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM;
23 (VII) A DESCRIPTION OF TRANSPARENCY MEASURES TAKEN
24 CONCERNING THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, INCLUDING ANY
25 MEASURES TAKEN TO DISCLOSE TO A CONSUMER THAT A HIGH–RISK ARTIFICIAL
26 INTELLIGENCE SYSTEM IS IN USE WHEN THE CONSUMER IS ENGAGING OR
27 INTERACTING WITH A SYSTEM OR PRODUCT IN WHICH A HIGH–RISK ARTIFICIAL
28 INTELLIGENCE SYSTEM IS IN USE;
29 (VIII) A DESCRIPTION OF POSTDEPLOYMENT MONITORING AND
30 USER SAFEGUARDS RELATED TO THE HIGH–RISK ARTIFICIAL INTELLIGENCE
31 SYSTEM, INCLUDING THE OVERSIGHT PROCESS ESTABLISHED BY THE DEPLOYER TO
32 ADDRESS ISSUES ARISING FROM DEPLOYMENT OR USE OF A HIGH–RISK ARTIFICIAL
33 INTELLIGENCE SYSTEM; AND
SENATE BILL 936 17
1 (IX) AN ANALYSIS OF THE VALIDITY AND RELIABILITY OF THE
2 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, IN ACCORDANCE WITH
3 CONTEMPORARY SOCIAL SCIENCE STANDARDS AND A DESCRIPTION OF METRICS TO
4 EVALUATE PERFORMANCE AND KNOWN LIMITATIONS OF THE HIGH–RISK
5 ARTIFICIAL INTELLIGENCE SYSTEM.
6 (3) A DEPLOYER SHALL MAINTAIN A COMPLETED IMPACT
7 ASSESSMENT OF A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM REQUIRED
8 UNDER THIS SECTION AND ALL RECORDS CONCERNING THE IMPACT ASSESSMENT
9 FOR AT LEAST 3 YEARS.
10 (4) A SINGLE IMPACT ASSESSMENT MAY ADDRESS A COMPARABLE
11 SET OF HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEMS DEPLOYED BY A DEPLOYER.
12 (D) BEGINNING FEBRUARY 1, 2026, BEFORE A DEPLOYER DEPLOYS A
13 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, THE DEPLOYER SHALL:
14 (1) NOTIFY THE CONSUMER THAT THE DEPLOYER HAS DEPLOYED A
15 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM TO MAKE, OR BE A SUBSTANTIAL
16 FACTOR IN MAKING, A CONSEQUENTIAL DECISION ABOUT THE CONSUMER; AND
17 (2) PROVIDE TO THE CONSUMER:
18 (I) A STATEMENT DISCLOSING THE PURPOSE OF THE
19 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM AND THE NATURE OF THE
20 CONSEQUENTIAL DECISION;
21 (II) IF APPLICABLE, INFORMATION CONCERNING THE
22 CONSUMER’S RIGHT TO OPT OUT OF THE PROCESSING OF THE CONSUMER’S
23 PERSONAL DATA IN ACCORDANCE WITH STATE OR FEDERAL LAW;
24 (III) CONTACT INFORMATION FOR THE DEPLOYER; AND
25 (IV) A DESCRIPTION, IN PLAIN LANGUAGE, OF THE HIGH–RISK
26 ARTIFICIAL INTELLIGENCE SYSTEM, INCLUDING:
27 1. THE PERSONAL CHARACTERISTICS OR ATTRIBUTES
28 THE ARTIFICIAL INTELLIGENCE SYSTEM WILL MEASURE OR ASSESS AND THE
29 METHOD BY WHICH THE SYSTEM MEASURES OR ASSESSES PERSONAL
30 CHARACTERISTICS OR ATTRIBUTES;
18 SENATE BILL 936
1 2. THE RELEVANCE OF PERSONAL CHARACTERISTICS
2 OR ATTRIBUTES TO CONSEQUENTIAL DECISIONS RELATED TO THE ARTIFICIAL
3 INTELLIGENCE SYSTEM;
4 3. ANY HUMAN COMPONENTS OF THE ARTIFICIAL
5 INTELLIGENCE SYSTEM;
6 4. THE MANNER IN WHICH AUTOMATED COMPONENTS
7 OF THE ARTIFICIAL INTELLIGENCE SYSTEM ARE USED TO INFORM CONSEQUENTIAL
8 DECISIONS RELATED TO THE SYSTEM; AND
9 5. A DIRECT LINK TO A PUBLICLY ACCESSIBLE WEBPAGE
10 ON THE DEPLOYER’S WEBSITE THAT CONTAINS A DESCRIPTION IN PLAIN LANGUAGE
11 OF THE LOGIC USED IN THE ARTIFICIAL INTELLIGENCE SYSTEM, INCLUDING:
12 A. KEY PARAMETERS THAT AFFECT THE OUTPUT OF THE
13 SYSTEM;
14 B. THE TYPE AND SOURCE OF DATA COLLECTED FROM
15 INDIVIDUALS AND PROCESSED BY THE SYSTEM IN MAKING OR ASSISTING IN MAKING
16 A CONSEQUENTIAL DECISION; AND
17 C. THE RESULTS OF THE MOST RECENT IMPACT
18 ASSESSMENT REQUIRED UNDER THIS SECTION.
19 (E) BEGINNING FEBRUARY 1, 2026, AND SUBJECT TO SUBSECTION (F) OF
20 THIS SECTION, A DEPLOYER THAT HAS DEPLOYED A HIGH–RISK ARTIFICIAL
21 INTELLIGENCE SYSTEM SHALL, IF A CONSEQUENTIAL DECISION IS ADVERSE TO THE
22 CONSUMER, PROVIDE TO THE CONSUMER:
23 (1) A STATEMENT DISCLOSING THE PRINCIPAL REASON OR REASONS
24 FOR THE ADVERSE CONSEQUENTIAL DECISION, INCLUDING:
25 (I) THE DEGREE TO WHICH, AND MANNER IN WHICH, THE
26 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM CONTRIBUTED TO THE ADVERSE
27 CONSEQUENTIAL DECISION;
28 (II) THE TYPE OF DATA THAT WERE PROCESSED BY THE
29 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM IN MAKING THE ADVERSE
30 CONSEQUENTIAL DECISION; AND
31 (III) THE SOURCE OF THE DATA DESCRIBED IN ITEM (II) OF THIS
32 ITEM; AND
SENATE BILL 936 19
1 (2) AN OPPORTUNITY TO:
2 (I) CORRECT ANY INCORRECT PERSONAL DATA THAT THE
3 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM PROCESSED IN MAKING, OR USED AS
4 A SUBSTANTIAL FACTOR IN MAKING, THE ADVERSE CONSEQUENTIAL DECISION; AND
5 (II) APPEAL THE ADVERSE CONSEQUENTIAL DECISION,
6 ALLOWING FOR HUMAN REVIEW UNLESS PROVIDING THIS OPPORTUNITY:
7 1. IS NOT IN THE BEST INTEREST OF THE CONSUMER; OR
8 2. MAY CAUSE A DELAY THAT POSES A RISK TO THE LIFE
9 OR SAFETY OF THE CONSUMER.
10 (F) THE DEPLOYER SHALL PROVIDE THE INFORMATION REQUIRED UNDER
11 SUBSECTION (E) OF THIS SUBSECTION:
12 (1) DIRECTLY TO THE CONSUMER;
13 (2) IN PLAIN LANGUAGE THAT IS TRANSLATED TO ANY LANGUAGES IN
14 WHICH THE DEPLOYER, IN THE ORDINARY COURSE OF SUCH DEPLOYER’S BUSINESS,
15 PROVIDES CONTRACTS, DISCLAIMERS, SALE ANNOUNCEMENTS, AND ANY OTHER
16 INFORMATION TO CONSUMERS; AND
17 (3) IN A FORMAT THAT IS ACCESSIBLE TO CONSUMERS WITH
18 DISABILITIES.
19 14–47A–05.
20 (A) THE REQUIREMENTS OF THIS SUBTITLE MAY NOT BE CONSTRUED TO
21 RESTRICT A DEVELOPER’S, A DEPLOYER’S, OR ANOTHER PERSON’S ABILITY TO:
22 (1) COMPLY WITH FEDERAL, STATE, OR LOCAL LAW;
23 (2) COMPLY WITH A CIVIL, CRIMINAL, OR REGULATORY INQUIRY, AN
24 INVESTIGATION, OR A SUBPOENA OR SUMMONS BY A FEDERAL, STATE, LOCAL, OR
25 OTHER GOVERNMENTAL AUTHORITY;
26 (3) COOPERATE WITH A LAW ENFORCEMENT AGENCY CONCERNING
27 CONDUCT OR ACTIVITY THAT THE DEVELOPER, DEPLOYER, OR OTHER PERSON
28 REASONABLY AND IN GOOD FAITH BELIEVES MAY VIOLATE FEDERAL, STATE, OR
29 LOCAL LAW;
20 SENATE BILL 936
1 (4) INVESTIGATE, ESTABLISH, EXERCISE, PREPARE FOR, OR DEFEND
2 A LEGAL CLAIM;
3 (5) TAKE IMMEDIATE STEPS TO PROTECT AN INTEREST THAT IS
4 ESSENTIAL FOR THE LIFE OR PHYSICAL SAFETY OF A CONSUMER OR ANOTHER
5 INDIVIDUAL;
6 (6) (I) BY ANY MEANS OTHER THAN FACIAL RECOGNITION
7 TECHNOLOGY, PREVENT, DETECT, PROTECT AGAINST, OR RESPOND TO:
8 1. A SECURITY INCIDENT;
9 2. A MALICIOUS OR DECEPTIVE ACTIVITY; OR
10 3. IDENTITY THEFT, FRAUD, HARASSMENT, OR ANY
11 OTHER ILLEGAL ACTIVITY;
12 (II) INVESTIGATE, REPORT, OR PROSECUTE THE PERSONS
13 RESPONSIBLE FOR ANY ACTION DESCRIBED IN ITEM (I) OF THIS ITEM; OR
14 (III) PRESERVE THE INTEGRITY OR SECURITY OF SYSTEMS;
15 (7) ENGAGE IN PUBLIC OR PEER–REVIEWED SCIENTIFIC OR
16 STATISTICAL RESEARCH IN THE PUBLIC INTEREST THAT:
17 (I) ADHERES TO ALL OTHER APPLICABLE ETHICS AND PRIVACY
18 LAWS; AND
19 (II) IS APPROVED, MONITORED, AND GOVERNED BY AN
20 INSTITUTIONAL REVIEW BOARD OR SIMILAR INDEPENDENT OVERSIGHT ENTITY
21 THAT DETERMINES:
22 1. WHETHER THE EXPECTED BENEFITS OF THE
23 RESEARCH OUTWEIGH THE RISKS ASSOCIATED WITH THE RESEARCH; AND
24 2. WHETHER THE DEVELOPER OR DEPLOYER HAS
25 IMPLEMENTED REASONABLE SAFEGUARDS TO MITIGATE THE RISKS ASSOCIATED
26 WITH THE RESEARCH;
27 (8) CONDUCT RESEARCH, TESTING, AND DEVELOPMENT ACTIVITIES
28 REGARDING AN ARTIFICIAL INTELLIGENCE SYSTEM OR MODEL, OTHER THAN
29 TESTING CONDUCTED UNDER REAL–WORLD CONDITIONS, BEFORE AN ARTIFICIAL
SENATE BILL 936 21
1 INTELLIGENCE SYSTEM OR MODEL IS PLACED ON THE MARKET, DEPLOYED OR PUT
2 INTO SERVICE, AS APPLICABLE;
3 (9) EFFECTUATE A PRODUCT RECALL;
4 (10) IDENTIFY AND REPAIR TECHNICAL ERRORS THAT IMPAIR
5 EXISTING OR INTENDED FUNCTIONALITY; OR
6 (11) ASSIST ANOTHER DEVELOPER, DEPLOYER, OR PERSON WITH ANY
7 OF THE OBLIGATIONS IMPOSED UNDER THIS SUBTITLE.
8 (B) THE OBLIGATIONS IMPOSED ON DEVELOPERS, DEPLOYERS, OR OTHER
9 PERSONS UNDER THIS SUBTITLE MAY NOT APPLY WHEN COMPLIANCE BY THE
10 DEVELOPER, DEPLOYER, OR OTHER PERSON WOULD VIOLATE AN EVIDENTIARY
11 PRIVILEGE UNDER THE LAWS OF THE STATE.
12 14–47A–06.
13 (A) A PERSON WHO VIOLATES THIS SUBTITLE IS SUBJECT TO A FINE NOT
14 EXCEEDING $1,000 AND, AS APPLICABLE, REASONABLE ATTORNEY’S FEES,
15 EXPENSES, AND COSTS, AS DETERMINED BY THE COURT.
16 (B) A PERSON WHO WILLFULLY VIOLATES THIS SUBTITLE IS SUBJECT TO A
17 FINE OF AT LEAST $1,000 AND NOT EXCEEDING $10,000 AND, AS APPLICABLE,
18 REASONABLE ATTORNEY’S FEES, EXPENSES, AND COSTS, AS DETERMINED BY THE
19 COURT.
20 (C) EACH VIOLATION OF THIS SUBTITLE IS A SEPARATE VIOLATION
21 SUBJECT TO THE CIVIL PENALTIES IMPOSED UNDER THIS SECTION.
22 14–47A–07.
23 (A) THE ATTORNEY GENERAL MAY ENFORCE THIS SUBTITLE.
24 (B) TO CARRY OUT THE REQUIREMENTS OF THIS SUBTITLE, THE ATTORNEY
25 GENERAL MAY:
26 (1) REQUIRE THAT A DEVELOPER DISCLOSE TO THE ATTORNEY
27 GENERAL:
28 (I) A STATEMENT OR DOCUMENTATION DESCRIBED IN THIS
29 SUBTITLE RELEVANT TO AN INVESTIGATION CONDUCTED BY THE ATTORNEY
30 GENERAL; AND
22 SENATE BILL 936
1 (II) A RISK MANAGEMENT POLICY DESIGNED AND
2 IMPLEMENTED, AN IMPACT ASSESSMENT COMPLETED, OR A RECORD MAINTAINED
3 UNDER THIS SUBTITLE RELEVANT TO AN INVESTIGATION CONDUCTED BY THE
4 ATTORNEY GENERAL;
5 (2) SUBJECT TO SUBSECTION (C) OF THIS SECTION, INITIATE A CIVIL
6 ACTION AGAINST A PERSON THAT VIOLATES THIS SUBTITLE; AND
7 (3) ADOPT REGULATIONS.
8 (C) (1) BEFORE BRINGING AN ACTION AGAINST A DEVELOPER OR
9 DEPLOYER FOR A VIOLATION OF THIS SUBTITLE, THE ATTORNEY GENERAL, IN
10 CONSULTATION WITH THE DEVELOPER OR DEPLOYER, SHALL DETERMINE IF IT IS
11 POSSIBLE TO CURE THE VIOLATION.
12 (2) IF IT IS POSSIBLE TO CURE THE VIOLATION, THE ATTORNEY
13 GENERAL MAY ISSUE A NOTICE OF VIOLATION TO THE DEVELOPER OR DEPLOYER
14 AND AFFORD THE DEVELOPER OR DEPLOYER THE OPPORTUNITY TO CURE THE
15 VIOLATION WITHIN 45 DAYS AFTER THE RECEIPT OF THE NOTICE OF VIOLATION.
16 (3) IN DETERMINING WHETHER TO GRANT A DEVELOPER OR
17 DEPLOYER AN OPPORTUNITY TO CURE A VIOLATION, THE ATTORNEY GENERAL
18 SHALL CONSIDER:
19 (I) THE NUMBER OF VIOLATIONS;
20 (II) THE SIZE AND COMPLEXITY OF THE DEVELOPER OR
21 DEPLOYER;
22 (III) THE NATURE AND EXTENT OF THE DEVELOPER’S OR
23 DEPLOYER’S BUSINESS;
24 (IV) WHETHER THERE IS A SUBSTANTIAL LIKELIHOOD OF
25 INJURY TO THE PUBLIC;
26 (V) THE SAFETY OF PERSONS OR PROPERTY; AND
27 (VI) WHETHER A VIOLATION WAS LIKELY CAUSED BY A HUMAN
28 OR TECHNICAL ERROR.
29 (4) IF A DEVELOPER OR DEPLOYER FAILS TO CURE A VIOLATION
30 WITHIN 45 DAYS AFTER THE RECEIPT OF A NOTICE OF VIOLATION UNDER
SENATE BILL 936 23
1 PARAGRAPH (3) OF THIS SUBSECTION, THE ATTORNEY GENERAL MAY PROCEED
2 WITH THE ACTION.
3 (D) IN AN ACTION BROUGHT BY THE ATTORNEY GENERAL UNDER THIS
4 SECTION, IT IS AN AFFIRMATIVE DEFENSE IF:
5 (1) A VIOLATION OF ANY PROVISION OF THIS SUBTITLE IS
6 DISCOVERED THROUGH RED–TEAMING, WHICH IS ADVERSARIAL TESTING
7 CONDUCTED FOR THE PURPOSE OF:
8 (I) IDENTIFYING THE POTENTIAL ADVERSE BEHAVIORS OR
9 OUTCOMES OF AN ARTIFICIAL INTELLIGENCE SYSTEM;
10 (II) IDENTIFYING HOW THE BEHAVIORS OR OUTCOMES OCCUR;
11 AND
12 (III) STRESS TESTING THE SAFEGUARDS AGAINST THE
13 BEHAVIORS OR OUTCOMES; AND
14 (2) NOT LATER THAN 45 DAYS AFTER DISCOVERING A VIOLATION
15 UNDER ITEM (1) OF THIS SUBSECTION, THE DEVELOPER OR DEPLOYER:
16 (I) CURES THE VIOLATION;
17 (II) PROVIDES NOTICE TO THE ATTORNEY GENERAL IN A FORM
18 AND MANNER PRESCRIBED BY THE ATTORNEY GENERAL THAT THE VIOLATION HAS
19 BEEN CURED AND EVIDENCE THAT ANY HARM CAUSED BY SUCH VIOLATION HAS
20 BEEN MITIGATED; AND
21 (III) IS OTHERWISE IN COMPLIANCE WITH THE REQUIREMENTS
22 OF THIS SUBTITLE.
23 14–47A–08.
24 A CONSUMER MAY BRING A CIVIL ACTION AGAINST A DEPLOYER IF:
25 (1) THE CONSUMER INITIALLY FILED A TIMELY ADMINISTRATIVE
26 CHARGE OR COMPLAINT UNDER FEDERAL, STATE, OR LOCAL LAW ALLEGING A
27 DISCRIMINATORY ACT BY THE DEPLOYER AS A RESULT OF A CONSEQUENTIAL
28 DECISION ABOUT THE CONSUMER THAT IS MADE BY A HIGH–RISK ARTIFICIAL
29 INTELLIGENCE SYSTEM OF THE DEPLOYER;
24 SENATE BILL 936
1 (2) AT LEAST 180 DAYS HAVE ELAPSED SINCE THE DATE OF FILING OF
2 THE ADMINISTRATIVE COMPLAINT; AND
3 (3) THE CIVIL ACTION IS FILED NOT MORE THAN 2 YEARS AFTER THE
4 OCCURRENCE OF THE ALLEGED DISCRIMINATORY ACT.
5 SECTION 2. AND BE IT FURTHER ENACTED, That, if any provision of this Act or
6 the application of any provision of this Act to any person or circumstance is held invalid for
7 any reason in a court of competent jurisdiction, the invalidity does not affect other
8 provisions or any other application of this Act that can be given effect without the invalid
9 provision or application, and for this purpose the provisions of this Act are declared
10 severable.
11 SECTION 3. AND BE IT FURTHER ENACTED, That this Act shall take effect
12 October 1, 2025.
[DELETED: :CA      5   C A C D F c h a i s t u r c t p c f k a r f r o c a d d p t t d o d r a d t m c d c m r a d t d i a m a r m u h a i s r a d t p c i h w a o t c c i a a a c c d a t A G t e t A a a c t b a c a a a d u c c s B  A S H  A  (  S T]
[DELETED:  S  A4.H–RAIDA.  IHI R N E C() N T S T F W H T M () ( “AL DN M T U O A O I T D A I O G O O T B O T ILS O GPS A O  () A;GE  () C;IO  () D;II  () E;VT  () G;E  () LE;II N  () N;IA  ()R;IA  () R;XE  () R;E  () S;IE  () S;IE  ()V;IES   ()CVL O P U TW]
[DELETED: S 3 ( “A”:N E  () T,,HR E HR DRS O DRS SFT T IY ME O’–, TW  () T,IH E O A AT A CR O A P T I D O R HN   () INC IICRA1442U.§20()   I I C      A() ( “A”R I SM M A MGB S T F A E O I OEST S S , ( “A I SM D N I ATG ()“C O DN M A D T H A L O S S E O T P OF ( P,,E N N  ( E;Y ( A; ( F;S ( A;S]
[DELETED:  S  ( H;G ( I; ( M;S  ( L.() ( “COR . ( “CR D N A I A I A() “D”ER  T O U A HHR A I S T M A T.() “D”ER  T O I A S M A HHRD D D N ,, T.() ( “G–”ELPL   () D;IY  () ISS   () IA B I I A V O D ( “G–LP A I ML D I A A I M T I U FT PG A R A B T() “GE A IE M ATO S T ,,.]
[DELETED: S 5() “GE A I SM M A() ( “H–IHR A I SM M A I S T I S I T ME O B A S F I MG A ( “H–HR A I SM D N  () NO   1 P;   2 Y   3 D A DNM P O ANMS ;   4 N   () T:IH   1  T T D N U   2 A IEE V G   3 A;   4 A;Y   5 C;S   6 C;Y   7 D;E]
[DELETED:  S    8 F;Y   9 I;N   1 I;G   1 N;G   1 S;G   1 S;   1 S;S   1 W;G   1 W;Y    1  T C WN M R O RS A A A I S T A A U P T P() ( “IN A S MN M A  () NN   () AI GLP A I M   1 A C O T GLP   2  C T P O TLPL ;   3  I A N R F]
[DELETED: S 7 ( “I A S MN D NHRM HRM ,:  () TH HHR A I SHRD D D D N ,,,R   () T:IH   1 I M T T HHR A I    2  P B T D O TR    3  A C W T I A O T HHR A I S  C 1().() ( “P”,EN M A IL A AN AE N Y P,,T E R E Y ,,. ( “P”.N () “P”RS HR ( H,,,W T T N ( M.() ( “SU FR M A F G B A  () H P B F M A CN ]
[DELETED:  S   () IA O A T O O A ( “SR T N N ,() “S”,YT N SS T O , B AS I B A A IT: ( E I A S W A HHR AE GG  U A A I S A B O F TT :  () TU.DC;H  E O  () TU.DD;IH  E EE   () TNAIH A E A P; ( A,R HR O D B A I F U I T B OE  NT1 A S T T P U I  O TE  ( A,,:R R   () IS A C E U T F EPAA1642U. O C C     010–, T D A T C F RS]
[DELETED: S 9  () P:IR   1  C R G B A I S I W A H C P I T T A T I T H CS    2  U A A IE L T Y,,() ( BF1,2,E E   A D O AHRN ( I A E A B B T TE  A D U R C A R U T I T D C W T P O T() BF1,2,(E E    D N HRR L E E R ,,,R HRM – ( AS D T I U O THR; ( D:G  () HHRM  F R O A D AHR;  () TIH P O T HHR AHRM]
[DELETED:  S   () I S D T M I W THR A I S W E FHRD D D N ,,,;  () VH K A F D O U O T HHRM   () TH M I W A I C U THRHR ( D:G  () TH M I W T HHR AE  D B T HHR A S W OD SD LD LD GN O,,,  () AI HL  () TIH I O O T HHR A  () VH K O R F R O AHRM ;  () TH M I W T HHR A S S B UD N UD A M B AD  (  A D T I R]
[DELETED: S 1  () UN T O O T HHRM   () MIO T P O T HHR() ( S()U S D O TN A DT  E   S S S S SF1,2,,,,, O M A T A D O O D AHR A I SM T T E PE, M A T D A O D T A I N F A D O T C B A D T C A I A  C E1(). (  D S M D A A A R U P  O T  () ARS I M C F T M A IYY ;  () D:IA   1  U T I U A H TT    2  I A P BA   () O.IT() ( FO A D R U T SN AR N L T  D A T D P A9 A S M T A HHR AM Y. ( AD T A S A A D F AHR A I S I N R T G D R U T S U T HHR I S I P T A U E]
[DELETED:  S () A HR S T A R U T S A AHR ( TAIR R N I ANI P B T A N O T A; ( SIC41   O T NS; TN  (  F F A I S T I E TO A A L A S AS TN() H ( T,§1 I A T ST A D I   O TE O O P F D U T OW  ( T:  () P;RR   () IE() ( AHR:  () RS   () C.IO]
[DELETED: S 1 ( F,O E C E L , O PM A M O HHR A I U P  O T S S B L I AM ( T(  O  () S:Y   1 C;   2  P T I T P O AT    3  U T M A R PT   () TIHHR   1    2 R T T E,,   3 P.() ( BF1,2E E   E D S UN ( I A E A B B T TE  A D U R C A R U T I T D C W T R O T]
[DELETED:  S () ( BF1,2,(E E     T SN A D O A HHR A IN T HRM. ( E, R M P DD ID M I A W P  O T S  () S,P T PS PS A PY E  D T I A R F O D O U T HHR A  () IEHRM ;  () IE R A I C O TF   1 TAIR R N I ANI P B T A N O T A;Y   2 SIC41    NS; T   3  N O I R M F F A IO S N   4  R M F F I S T T T E MO S    ( AHHR A I S S B T S T R U T S A AHR]
[DELETED: S 1  () TAIRH R N I ANI P B T A N O T A;  () SIC41IT   O T NS; TN   () IN N O I R M F F A IO S N.() ( S()(U      ):  () OF1,2N O A E   B I O A HHR A I S O U O AHRM HRM ;  () A9IT  D A S THRE  C A I A O T HHR AHR:   1  S C T T U O K F O T HHR A IM    2  N ( E(   ()  S B T D D TF Y HR–;]
[DELETED:  S   () IN A O W T D O THR:   1    2  N O A AN    3  S T H B T T M  () IO A P I AN HRM D,H M RS,HR;  () AV D O T C O D THR A I S P A I A THR;  () IF T D U D T C THRM  D T D U T C T HHR A  () I HR;  () I D O T M THRM HR S I I U W T C I E O W A S O P I W A HHR A  ()I D O P M A S R T T HHR A IM HRM ]
[DELETED: S 1  () XNHR A I SM I A W P A K L O T HHR ( D S M A C I O A HHR A I S R  . ( S I A M A A CHR.() BF1,2,E E   B A D D AHRM ,: ( HR A I S T ME O B A SG R ; ( P:  () A S D T P O THR A I S A T N O TN  () IIF AE I C TRS R T O O O T P O T CRS T;  () C;IOR   () A,,V N E HRM :   1  P C O A A I S W M O A A T B W T S M O A P]
[DELETED:  S    2  R O P C A T C D R T T A   3  H C O T A   4  M I W A CM    5 RSM :   A    B N    C  R O T M R IN() BF1,2,(E E    F  SN A D T H D A HHR AL R : ( N G:  () T,H D T WH A M I WH THR A I S C T T A  () TIH T O D T W P B THR A I S I M T AN   () T(IH II M ]
[DELETED: S 1 ( A:  () O A I P D T THRG G N ;  () AIP T A C DN   1 I;R    2 () H E ): ( D; ( R RSS’ CS DS S AS A A O,S  ()N A F T I A T C W() HRS RS NS,’,’: ( C,S,;L TE  ( C,,L L Y N L TE L ,S, (  O A T T DR DR O O P FL TE OS]
[DELETED:  S  ( I,,,E H E R  (  I S T P A I T I F T L O P S O A C O A ( () Y A M O T F RY T T T O,,,:   1 A;   2 A;Y    3 I,, TT FD HT O AY  () I,INE RT O P T P I M );  () P;IR ()EN I P O PRR S O  () DS   () I,IS AD MD A G B A R B O S I O E   1  T E B O TH    2  T D O D H R S T M T R A ( C,H G  A A I S O ML O TLWS ]
[DELETED: S 2T E ; ( E; (  A R T E T IY  ( A,R R () T,HS S  U T S M N A W C B TR DR O O P W V A E T.()    AD A AE R AYS FS0,,’S S T,.()   O A L  A N E  AD A AE0$0,YSS S S ,,T() A V O T S I A S VN() TAG.H T E() T,OE  T: ( R T A D D T T T:  ()  S O D D I T R T A I C B T T;L ]
[DELETED:  S   () I R M P D AD D  T S R T A I C B TG; E ( S() C N E  ( A.() ( E B A A A A D O F A V O T SE T T EL IAGR N ( I, I I P T C T VN T T A T D O D T O T C T  N5. (  D W T G A D O A O T C A VN T T EAR  () T;HS  () IH S A C O T D O  () TIH N A E O T DRS ORSS;  () VH T I A S L OC  () T;HY   () IHR (  A D O D F T C A V  D A T R O A N O V U]
[DELETED: S 2  O T SN T T E M P),AN() IAN A A B B T T E U TN : ( V O A P O T S I T RDTG W I A T  () D T P A B O  () IIDR  () IT T T S A TS  ( N4 L T  D A D A V  N R),:  () C;UN  () PAIR T E T E C A T A H C B S HD   () ISEA: (  C I F A T A O C U FL TE O L L A AS A B T D A A R O A C A T C T I M B A HHR A]
[DELETED:  S  ( A1  T  ( T  T  S t a r i a c o c j t i d n a o p p o a a f t p t p o t A a d s  S A B I F E T t A s t e O]


================================================================================

Raw Text:
SENATE BILL 936
I3, S1 5lr0853
CF 5lr3153
By: Senators Hester, Gile, and Love
Introduced and read first time: January 28, 2025
Assigned to: Finance
A BILL ENTITLED
1 AN ACT concerning
2 Consumer Protection – High–Risk Artificial Intelligence – Developer and
3 Deployer Requirements
4 FOR the purpose of requiring a certain developer of and a certain deployer who uses a
5 certain high–risk artificial intelligence system to use reasonable care to protect
6 consumers from known and reasonably foreseeable risks of certain algorithmic
7 discrimination; prohibiting a developer from providing to a certain deployer or other
8 developer a high–risk artificial intelligence system unless certain disclosures are
9 provided to the deployer or developer; requiring a developer to make certain
10 documentation and information available to complete an impact assessment in a
11 certain manner; requiring a deployer to design, implement, and maintain a risk
12 management policy and program for the high–risk artificial intelligence system in
13 use by the deployer; requiring a deployer to complete an impact assessment of its
14 high–risk artificial intelligence system; requiring a deployer to provide certain
15 information to a consumer regarding the deployment of and decisions made by a
16 high–risk artificial intelligence system; requiring a deployer to provide consumers
17 with an opportunity to correct certain information and appeal a certain
18 consequential decision; authorizing the Attorney General to enforce this Act;
19 authorizing a consumer to bring a civil action against a deployer under certain
20 circumstances; and generally relating to the use of high–risk artificial intelligence
21 systems in the State.
22 BY adding to
23 Article – Commercial Law
24 Section 14–47A–01 through 14–47A–08 to be under the new subtitle “Subtitle 47A.
25 High–Risk Artificial Intelligence Developer Act”
26 Annotated Code of Maryland
27 (2013 Replacement Volume and 2024 Supplement)
28 SECTION 1. BE IT ENACTED BY THE GENERAL ASSEMBLY OF MARYLAND,
29 That the Laws of Maryland read as follows:
EXPLANATION: CAPITALS INDICATE MATTER ADDED TO EXISTING LAW.
[Brackets] indicate matter deleted from exist in g l aw . *sb0936*

2 SENATE BILL 936
1 Article – Commercial Law
2 SUBTITLE 47A. HIGH–RISK ARTIFICIAL INTELLIGENCE DEVELOPER ACT.
3 14–47A–01.
4 (A) IN THIS SUBTITLE THE FOLLOWING WORDS HAVE THE MEANINGS
5 INDICATED.
6 (B) (1) “ALGORITHMIC DISCRIMINATION” MEANS THE USE OF AN
7 ARTIFICIAL INTELLIGENCE SYSTEM THAT RESULTS IN AN UNLAWFUL DIFFERENTIAL
8 TREATMENT OR IMPACT THAT DISFAVORS AN INDIVIDUAL OR GROUP OF
9 INDIVIDUALS ON THE BASIS OF THE INDIVIDUAL’S OR GROUP’S ACTUAL OR
10 PERCEIVED:
11 (I) AGE;
12 (II) COLOR;
13 (III) DISABILITY;
14 (IV) ETHNICITY;
15 (V) GENETIC INFORMATION;
16 (VI) LIMITED PROFICIENCY IN THE ENGLISH LANGUAGE;
17 (VII) NATIONAL ORIGIN;
18 (VIII) RACE;
19 (IX) RELIGION;
20 (X) REPRODUCTIVE HEALTH;
21 (XI) SEX;
22 (XII) SEXUAL ORIENTATION;
23 (XIII) VETERAN STATUS; OR
24 (XIV) CLASSIFICATION OTHERWISE PROTECTED UNDER STATE
25 OR FEDERAL LAW.

SENATE BILL 936 3
1 (2) “ALGORITHMIC DISCRIMINATION” DOES NOT INCLUDE:
2 (I) THE OFFER, LICENSE, OR USE OF A HIGH–RISK ARTIFICIAL
3 INTELLIGENCE SYSTEM BY A DEVELOPER OR DEPLOYER FOR THE SOLE PURPOSE OF
4 THE DEVELOPER’S OR DEPLOYER’S SELF–TESTING TO IDENTIFY, MITIGATE, OR
5 PREVENT DISCRIMINATION OR OTHERWISE ENSURE COMPLIANCE WITH STATE AND
6 FEDERAL LAW;
7 (II) THE EXPANSION OF AN APPLICANT, A CUSTOMER, OR A
8 PARTICIPANT POOL TO INCREASE DIVERSITY OR REDRESS HISTORICAL
9 DISCRIMINATION; OR
10 (III) AN ACT OR OMISSION BY OR ON BEHALF OF A PRIVATE CLUB
11 OR OTHER ESTABLISHMENT NOT IN FACT OPEN TO THE PUBLIC, AS PROVIDED BY
12 TITLE II OF THE CIVIL RIGHTS ACT OF 1964 UNDER 42 U.S.C. § 2000A(E).
13 (C) (1) “ARTIFICIAL INTELLIGENCE SYSTEM” MEANS A MACHINE
14 LEARNING–BASED SYSTEM THAT FOR ANY EXPLICIT OR IMPLICIT OBJECTIVE,
15 INFERS FROM THE INPUTS THE SYSTEM RECEIVES HOW TO GENERATE OUTPUTS,
16 INCLUDING CONTENT, DECISIONS, PREDICTIONS, OR RECOMMENDATIONS THAT CAN
17 INFLUENCE PHYSICAL OR VIRTUAL ENVIRONMENTS.
18 (2) “ARTIFICIAL INTELLIGENCE SYSTEM” DOES NOT INCLUDE AN
19 ARTIFICIAL INTELLIGENCE SYSTEM OR A MODEL THAT IS USED FOR DEVELOPMENT,
20 PROTOTYPING, AND RESEARCH ACTIVITIES BEFORE THE ARTIFICIAL INTELLIGENCE
21 SYSTEM OR MODEL IS RELEASED ON THE MARKET.
22 (D) “CONSEQUENTIAL DECISION” MEANS A DECISION THAT HAS A
23 MATERIALLY LEGAL OR SIMILARLY SIGNIFICANT EFFECT ON THE PROVISION OR
24 DENIAL TO A CONSUMER OF:
25 (1) PAROLE, PROBATION, A PARDON, OR ANY OTHER RELEASE FROM
26 INCARCERATION OR COURT SUPERVISION;
27 (2) EDUCATION ENROLLMENT OR EDUCATION OPPORTUNITY;
28 (3) ACCESS TO OR PROVISION OF EMPLOYMENT;
29 (4) FINANCIAL OR LENDING SERVICES;
30 (5) ACCESS TO OR THE PROVISION OF HEALTH CARE SERVICES;

4 SENATE BILL 936
1 (6) HOUSING;
2 (7) INSURANCE;
3 (8) MARITAL STATUS; OR
4 (9) LEGAL SERVICE.
5 (E) (1) “CONSUMER” MEANS AN INDIVIDUAL WHO IS A RESIDENT OF THE
6 STATE AND IS ACTING ONLY IN A PERSONAL OR HOUSEHOLD CONTEXT.
7 (2) “CONSUMER” DOES NOT INCLUDE AN INDIVIDUAL ACTING IN A
8 COMMERCIAL OR EMPLOYMENT CONTEXT.
9 (F) “DEPLOYER” MEANS A PERSON DOING BUSINESS IN THE STATE THAT
10 DEPLOYS OR USES A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM TO MAKE A
11 CONSEQUENTIAL DECISION IN THE STATE.
12 (G) “DEVELOPER” MEANS A PERSON DOING BUSINESS IN THE STATE THAT
13 DEVELOPS OR INTENTIONALLY AND SUBSTANTIALLY MODIFIES A HIGH–RISK
14 ARTIFICIAL INTELLIGENCE SYSTEM THAT IS OFFERED, SOLD, LEASED, GIVEN, OR
15 OTHERWISE PROVIDED TO CONSUMERS IN THE STATE.
16 (H) (1) “GENERAL–PURPOSE ARTIFICIAL INTELLIGENCE MODEL” MEANS
17 A MODEL USED BY AN ARTIFICIAL INTELLIGENCE SYSTEM THAT:
18 (I) DISPLAYS SIGNIFICANT GENERALITY;
19 (II) IS CAPABLE OF COMPETENTLY PERFORMING A WIDE RANGE
20 OF DISTINCT TASKS; AND
21 (III) CAN BE INTEGRATED INTO A VARIETY OF DOWNSTREAM
22 APPLICATIONS OR SYSTEMS.
23 (2) “GENERAL–PURPOSE ARTIFICIAL INTELLIGENCE MODEL” DOES
24 NOT INCLUDE AN ARTIFICIAL INTELLIGENCE MODEL THAT IS USED FOR
25 DEVELOPMENT, PROTOTYPING, AND RESEARCH ACTIVITIES BEFORE THE
26 ARTIFICIAL INTELLIGENCE MODEL IS RELEASED ON THE MARKET.
27 (I) “GENERATIVE ARTIFICIAL INTELLIGENCE” MEANS ARTIFICIAL
28 INTELLIGENCE THAT IS CAPABLE OF AND USED TO PRODUCE SYNTHETIC CONTENT,
29 INCLUDING AUDIO, IMAGES, TEXT, AND VIDEOS.

SENATE BILL 936 5
1 (J) “GENERATIVE ARTIFICIAL INTELLIGENCE SYSTEM” MEANS ANY
2 ARTIFICIAL INTELLIGENCE SYSTEM OR SERVICE THAT INCORPORATES GENERATIVE
3 ARTIFICIAL INTELLIGENCE.
4 (K) (1) “HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM” MEANS AN
5 ARTIFICIAL INTELLIGENCE SYSTEM THAT IS SPECIFICALLY INTENDED TO
6 AUTONOMOUSLY MAKE, OR BE A SUBSTANTIAL FACTOR IN MAKING, A
7 CONSEQUENTIAL DECISION.
8 (2) “HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM” DOES NOT
9 INCLUDE:
10 (I) AN ARTIFICIAL INTELLIGENCE SYSTEM THAT IS INTENDED
11 TO:
12 1. PERFORM A NARROW PROCEDURAL TASK;
13 2. IMPROVE THE RESULT OF A PREVIOUSLY COMPLETED
14 HUMAN ACTIVITY;
15 3. DETECT ANY DECISION–MAKING PATTERNS OR ANY
16 DEVIATIONS FROM PREEXISTING DECISION–MAKING PATTERNS; OR
17 4. PERFORM A PREPARATORY TASK TO AN ASSESSMENT
18 RELEVANT TO A CONSEQUENTIAL DECISION; OR
19 (II) THE FOLLOWING TECHNOLOGIES:
20 1. ANTIFRAUD TECHNOLOGY THAT DOES NOT USE
21 FACIAL RECOGNITION TECHNOLOGY;
22 2. ARTIFICIAL INTELLIGENCE–ENABLED VIDEO GAME
23 TECHNOLOGY;
24 3. ANTIMALWARE AND ANTIVIRUS TECHNOLOGY;
25 4. AUTONOMOUS VEHICLE TECHNOLOGY;
26 5. CALCULATORS;
27 6. CYBERSECURITY TECHNOLOGY;
28 7. DATABASES AND DATA STORAGE;

6 SENATE BILL 936
1 8. FIREWALL TECHNOLOGY;
2 9. INTERNET DOMAIN REGISTRATION;
3 10. INTERNET WEBSITE LOADING;
4 11. NETWORKING;
5 12. SPAM AND ROBOCALL FILTERING;
6 13. SPELLCHECKING TECHNOLOGY;
7 14. SPREADSHEETS;
8 15. WEB CACHING;
9 16. WEB HOSTING OR SIMILAR TECHNOLOGY; OR
10 17. TECHNOLOGY THAT COMMUNICATES WITH
11 CONSUMERS IN NATURAL LANGUAGE FOR THE PURPOSE OF PROVIDING USERS WITH
12 INFORMATION, MAKING REFERRALS OR RECOMMENDATIONS, AND ANSWERING
13 QUESTIONS AND IS SUBJECT TO AN ACCEPTABLE USE POLICY THAT PROHIBITS
14 GENERATING CONTENT THAT IS DISCRIMINATORY OR UNLAWFUL.
15 (L) (1) “INTENTIONAL AND SUBSTANTIAL MODIFICATION” MEANS A
16 DELIBERATE CHANGE MADE TO:
17 (I) AN ARTIFICIAL INTELLIGENCE SYSTEM THAT RESULTS IN A
18 NEW MATERIAL RISK OF ALGORITHMIC DISCRIMINATION; OR
19 (II) A GENERAL–PURPOSE ARTIFICIAL INTELLIGENCE MODEL
20 THAT:
21 1. AFFECTS COMPLIANCE OF THE GENERAL–PURPOSE
22 ARTIFICIAL INTELLIGENCE MODEL;
23 2. MATERIALLY CHANGES THE PURPOSE OF THE
24 GENERAL–PURPOSE ARTIFICIAL INTELLIGENCE MODEL; OR
25 3. RESULTS IN ANY NEW REASONABLY FORESEEABLE
26 RISK OF ALGORITHMIC DISCRIMINATION.

SENATE BILL 936 7
1 (2) “INTENTIONAL AND SUBSTANTIAL MODIFICATION” DOES NOT
2 INCLUDE A CHANGE MADE TO A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, OR
3 THE PERFORMANCE OF A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, IF:
4 (I) THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM
5 CONTINUES TO LEARN AFTER THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM IS
6 DEPLOYED OR OFFERED, SOLD, LEASED, LICENSED, GIVEN, OR OTHERWISE MADE
7 AVAILABLE TO A DEPLOYER; AND
8 (II) THE CHANGE:
9 1. IS MADE TO THE HIGH–RISK ARTIFICIAL
10 INTELLIGENCE SYSTEM AS A RESULT OF ANY LEARNING DESCRIBED IN ITEM (I) OF
11 THIS PARAGRAPH;
12 2. WAS PREDETERMINED BY THE DEPLOYER OR THE
13 THIRD PARTY CONTRACTED BY THE DEPLOYER; AND
14 3. INCLUDED AND CONCLUDED WITHIN THE INITIAL
15 IMPACT ASSESSMENT OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM
16 UNDER § 14–47A–04(C) OF THIS SUBTITLE.
17 (M) (1) “PERSON” MEANS AN INDIVIDUAL, AN ASSOCIATION, A
18 COOPERATIVE, A CORPORATION, A LIMITED LIABILITY COMPANY, A PARTNERSHIP,
19 A TRUST, A JOINT VENTURE, OR ANY OTHER LEGAL OR COMMERCIAL ENTITY AND
20 ANY SUCCESSOR, REPRESENTATIVE, AGENCY, OR INSTRUMENTALITY THEREOF.
21 (2) “PERSON” DOES NOT INCLUDE A GOVERNMENTAL UNIT.
22 (N) “PRINCIPAL BASIS” MEANS THE USE OF AN OUTPUT OF A HIGH–RISK
23 ARTIFICIAL INTELLIGENCE SYSTEM TO MAKE A DECISION WITHOUT:
24 (1) HUMAN REVIEW, OVERSIGHT, INVOLVEMENT, OR INTERVENTION;
25 OR
26 (2) MEANINGFUL CONSIDERATION BY A HUMAN.
27 (O) (1) “SUBSTANTIAL FACTOR” MEANS A FACTOR GENERATED BY AN
28 ARTIFICIAL INTELLIGENCE SYSTEM THAT IS:
29 (I) THE PRINCIPAL BASIS FOR MAKING A CONSEQUENTIAL
30 DECISION; OR

8 SENATE BILL 936
1 (II) CAPABLE OF ALTERING THE OUTCOME OF A
2 CONSEQUENTIAL DECISION.
3 (2) “SUBSTANTIAL FACTOR” INCLUDES ANY USE OF AN ARTIFICIAL
4 INTELLIGENCE SYSTEM TO GENERATE ANY CONTENT, DECISION, PREDICTION, OR
5 RECOMMENDATION CONCERNING A CONSUMER THAT IS USED AS THE PRINCIPAL
6 BASIS TO MAKE A CONSEQUENTIAL DECISION CONCERNING THE CONSUMER.
7 (P) “SYNTHETIC CONTENT” MEANS INFORMATION, SUCH AS AUDIO CLIPS,
8 IMAGES, TEXT, AND VIDEO, THAT IS PRODUCED OR SIGNIFICANTLY MODIFIED OR
9 GENERATED BY ALGORITHMS, INCLUDING BY AN ARTIFICIAL INTELLIGENCE
10 SYSTEM.
11 14–47A–02.
12 THIS SUBTITLE DOES NOT APPLY TO:
13 (1) EXCEPT IN A SITUATION WHERE A HIGH–RISK ARTIFICIAL
14 INTELLIGENCE SYSTEM IS USED TO MAKE, OR IS A SUBSTANTIAL FACTOR IN MAKING,
15 A DECISION CONCERNING EMPLOYMENT OR HOUSING, A DEVELOPER OR DEPLOYER
16 THAT USES AN ARTIFICIAL INTELLIGENCE SYSTEM ACQUIRED BY OR FOR THE
17 FEDERAL GOVERNMENT OR ANY FEDERAL AGENCY OR DEPARTMENT, INCLUDING:
18 (I) THE U.S. DEPARTMENT OF COMMERCE;
19 (II) THE U.S. DEPARTMENT OF DEFENSE; AND
20 (III) THE NATIONAL AERONAUTICS AND SPACE
21 ADMINISTRATION;
22 (2) AN INSURER, OR A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM
23 DEVELOPED OR DEPLOYED BY AN INSURER FOR USE IN THE BUSINESS OF
24 INSURANCE, IF THE INSURER IS REGULATED AND SUPERVISED BY THE INSURANCE
25 ADMINISTRATION AND SUBJECT TO THE PROVISIONS UNDER TITLE 13 OF THIS
26 ARTICLE; OR
27 (3) A DEVELOPER, A DEPLOYER, OR ANY OTHER PERSON WHO:
28 (I) IS A COVERED ENTITY UNDER THE FEDERAL HEALTH
29 INSURANCE PORTABILITY AND ACCOUNTABILITY ACT OF 1996 UNDER 42 U.S.C. §
30 1320D THROUGH 1320D–9, AND THE CORRESPONDING FEDERAL REGULATIONS;
31 AND

SENATE BILL 936 9
1 (II) PROVIDES:
2 1. HEALTH CARE RECOMMENDATIONS GENERATED BY
3 AN ARTIFICIAL INTELLIGENCE SYSTEM IN WHICH A HEALTH CARE PROVIDER IS
4 REQUIRED TO TAKE ACTION TO IMPLEMENT THE HEALTH CARE
5 RECOMMENDATIONS; OR
6 2. SERVICES USING AN ARTIFICIAL INTELLIGENCE
7 SYSTEM FOR AN ADMINISTRATIVE, FINANCIAL, QUALITY MEASUREMENT, SECURITY,
8 OR PERFORMANCE IMPROVEMENT FUNCTION.
9 14–47A–03.
10 (A) (1) BEGINNING FEBRUARY 1, 2026, A DEVELOPER OF A
11 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM SHALL USE REASONABLE CARE TO
12 PROTECT CONSUMERS FROM ANY KNOWN OR REASONABLY FORESEEABLE RISKS OF
13 ALGORITHMIC DISCRIMINATION.
14 (2) IN AN ENFORCEMENT ACTION BROUGHT BY THE ATTORNEY
15 GENERAL UNDER THIS SUBTITLE, THERE SHALL BE A REBUTTABLE PRESUMPTION
16 THAT A DEVELOPER USED REASONABLE CARE AS REQUIRED UNDER THIS
17 SUBSECTION IF THE DEVELOPER COMPLIED WITH THE PROVISIONS OF THIS
18 SECTION.
19 (B) BEGINNING FEBRUARY 1, 2026, AND SUBJECT TO SUBSECTION (D) OF
20 THIS SECTION, A DEVELOPER OF A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM
21 MAY NOT OFFER, SELL, LEASE, GIVE, OR OTHERWISE PROVIDE TO A DEPLOYER, OR
22 OTHER DEVELOPER, A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, UNLESS THE
23 DEVELOPER MAKES AVAILABLE TO THE DEPLOYER OR OTHER DEVELOPER:
24 (1) A STATEMENT DISCLOSING THE INTENDED USES OF THE
25 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM;
26 (2) DOCUMENTATION DISCLOSING:
27 (I) THE KNOWN OR REASONABLY FORESEEABLE LIMITATIONS
28 OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, INCLUDING THE KNOWN OR
29 REASONABLY FORESEEABLE RISKS OF ALGORITHMIC DISCRIMINATION ARISING
30 FROM THE INTENDED USES OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM;
31 (II) THE PURPOSE OF THE HIGH–RISK ARTIFICIAL
32 INTELLIGENCE SYSTEM AND THE INTENDED BENEFITS AND USES OF THE HIGH–RISK
33 ARTIFICIAL INTELLIGENCE SYSTEM;

10 SENATE BILL 936
1 (III) A SUMMARY DESCRIBING THE MANNER IN WHICH THE
2 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM WAS EVALUATED FOR
3 PERFORMANCE BEFORE THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM WAS
4 LICENSED, SOLD, LEASED, GIVEN, OR OTHERWISE MADE AVAILABLE TO A DEPLOYER;
5 (IV) THE MEASURES THE DEVELOPER HAS TAKEN TO MITIGATE
6 REASONABLY FORESEEABLE RISKS OF ALGORITHMIC DISCRIMINATION THAT THE
7 DEVELOPER KNOWS ARISES FROM DEPLOYMENT OR USE OF THE HIGH–RISK
8 ARTIFICIAL INTELLIGENCE SYSTEM; AND
9 (V) THE MANNER IN WHICH AN INDIVIDUAL CAN USE THE
10 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM AND MONITOR THE PERFORMANCE
11 OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM FOR RISK OF ALGORITHMIC
12 DISCRIMINATION;
13 (3) DOCUMENTATION DESCRIBING:
14 (I) THE MANNER IN WHICH THE HIGH–RISK ARTIFICIAL
15 INTELLIGENCE SYSTEM WAS EVALUATED FOR PERFORMANCE, AND MITIGATION OF
16 ALGORITHMIC DISCRIMINATION BEFORE THE HIGH–RISK ARTIFICIAL
17 INTELLIGENCE SYSTEM WAS OFFERED, SOLD, LEASED, LICENSED, GIVEN, OR
18 OTHERWISE MADE AVAILABLE TO THE DEPLOYER OR OTHER DEVELOPER;
19 (II) A HIGH–LEVEL SUMMARY OF THE MANNER IN WHICH DATA
20 SOURCES WERE EVALUATED FOR POTENTIAL BIAS AND APPROPRIATE MITIGATIONS
21 WERE APPLIED;
22 (III) THE INTENDED OUTPUTS OF THE HIGH–RISK ARTIFICIAL
23 INTELLIGENCE SYSTEM;
24 (IV) THE MEASURES THE DEVELOPER HAS TAKEN TO MITIGATE
25 ANY KNOWN OR REASONABLY FORESEEABLE RISKS OF ALGORITHMIC
26 DISCRIMINATION THAT MAY ARISE FROM REASONABLY FORESEEABLE DEPLOYMENT
27 OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM; AND
28 (V) THE MANNER IN WHICH THE HIGH–RISK ARTIFICIAL
29 INTELLIGENCE SYSTEM SHOULD BE USED, NOT USED, AND MONITORED BY AN
30 INDIVIDUAL WHEN BEING USED; AND
31 (4) ANY ADDITIONAL DOCUMENTATION THAT IS REASONABLY
32 NECESSARY TO ASSIST A DEPLOYER TO:

SENATE BILL 936 11
1 (I) UNDERSTAND THE OUTPUTS OF THE HIGH–RISK
2 ARTIFICIAL INTELLIGENCE SYSTEM; AND
3 (II) MONITOR THE PERFORMANCE OF THE HIGH–RISK
4 ARTIFICIAL INTELLIGENCE SYSTEM FOR RISKS OF ALGORITHMIC DISCRIMINATION.
5 (C) (1) SUBJECT TO SUBSECTION (D) OF THIS SECTION, A DEVELOPER
6 THAT, ON OR AFTER FEBRUARY 1, 2026, OFFERS, SELLS, LEASES, LICENSES, GIVES,
7 OR OTHERWISE MAKES AVAILABLE TO A DEPLOYER OR OTHER DEVELOPER A
8 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, TO THE EXTENT PRACTICABLE,
9 SHALL MAKE AVAILABLE TO DEPLOYERS AND OTHER DEVELOPERS THE
10 DOCUMENTATION AND INFORMATION NECESSARY FOR A DEPLOYER OR THIRD
11 PARTY CONTRACTED BY A DEPLOYER TO COMPLETE AN IMPACT ASSESSMENT
12 UNDER § 14–47A–04(C) OF THIS SUBTITLE.
13 (2) THE DEVELOPER SHALL MAKE DOCUMENTATION AND
14 INFORMATION AVAILABLE AS REQUIRED UNDER PARAGRAPH (1) OF THIS
15 SUBSECTION THROUGH:
16 (I) ARTIFACTS, INCLUDING MODEL CARD FILES THAT
17 ACCOMPANY THE MODEL AND PROVIDE INFORMATION ABOUT DISCOVERABILITY,
18 REPRODUCIBILITY, AND SHARING;
19 (II) DATASET CARD FILES THAT:
20 1. ARE USED TO INFORM USERS ABOUT HOW TO
21 RESPONSIBLY USE THE DATA IN A DATASET; AND
22 2. CONTAIN INFORMATION ABOUT POTENTIAL BIASES
23 OF THE DATA; OR
24 (III) OTHER IMPACT ASSESSMENTS.
25 (D) (1) FOR ANY DISCLOSURE REQUIRED UNDER THIS SECTION, A
26 DEVELOPER, NOT LATER THAN 90 DAYS AFTER THE DEVELOPER PERFORMS AN
27 INTENTIONAL AND SUBSTANTIAL MODIFICATION TO A HIGH–RISK ARTIFICIAL
28 INTELLIGENCE SYSTEM, SHALL UPDATE THE DISCLOSURE TO ENSURE ACCURACY.
29 (2) A DEVELOPER THAT ALSO SERVES AS A DEPLOYER FOR ANY
30 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM IS NOT REQUIRED TO GENERATE
31 THE DOCUMENTATION REQUIRED UNDER THIS SECTION UNLESS THE HIGH–RISK
32 ARTIFICIAL INTELLIGENCE SYSTEM IS PROVIDED TO AN UNAFFILIATED ENTITY
33 ACTING AS A DEPLOYER OR AS OTHERWISE REQUIRED BY LAW.

12 SENATE BILL 936
1 (E) A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM SHALL BE PRESUMED
2 TO SATISFY THE APPLICABLE REQUIREMENTS UNDER THIS SECTION AND ANY
3 REGULATIONS ADOPTED IN ACCORDANCE WITH THIS SUBTITLE IF THE HIGH–RISK
4 ARTIFICIAL INTELLIGENCE SYSTEM IS IN CONFORMITY WITH THE LATEST VERSION
5 OF:
6 (1) THE ARTIFICIAL INTELLIGENCE RISK MANAGEMENT
7 FRAMEWORK PUBLISHED BY THE NATIONAL INSTITUTE OF STANDARDS AND
8 TECHNOLOGY;
9 (2) STANDARD ISO/IEC 42001 OF THE INTERNATIONAL
10 ORGANIZATION FOR STANDARDIZATION; OR
11 (3) ANOTHER NATIONALLY OR INTERNATIONALLY RECOGNIZED RISK
12 MANAGEMENT FRAMEWORK FOR ARTIFICIAL INTELLIGENCE SYSTEMS THAT IS
13 SUBSTANTIALLY EQUIVALENT TO, AND AT LEAST AS STRINGENT AS, THE
14 REQUIREMENTS ESTABLISHED UNDER THIS SECTION.
15 (F) THIS SECTION MAY NOT BE CONSTRUED TO REQUIRE A DEVELOPER TO
16 DISCLOSE ANY INFORMATION:
17 (1) THAT IS A TRADE SECRET, AS DEFINED IN § 11–1201 OF THIS
18 ARTICLE, OR OTHERWISE PROTECTED FROM DISCLOSURE UNDER STATE OR
19 FEDERAL LAW; OR
20 (2) THE DISCLOSURE OF WHICH WOULD:
21 (I) PRESENT A SECURITY RISK TO THE DEVELOPER; OR
22 (II) REQUIRE THE DEVELOPER TO DISCLOSE CONFIDENTIAL OR
23 PROPRIETARY INFORMATION.
24 (G) (1) EACH DEVELOPER OF A GENERATIVE ARTIFICIAL INTELLIGENCE
25 SYSTEM THAT GENERATES OR MODIFIES SYNTHETIC CONTENT SHALL ENSURE THAT
26 THE OUTPUTS OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM:
27 (I) ARE MARKED AT THE TIME THE OUTPUT IS GENERATED AND
28 IN A MANNER THAT IS DETECTABLE BY CONSUMERS; AND
29 (II) COMPLY WITH ANY ACCESSIBILITY REQUIREMENTS.

SENATE BILL 936 13
1 (2) FOR SYNTHETIC CONTENT THAT IS AN AUDIO, IMAGE, OR VIDEO
2 FORMED AS PART OF AN ARTISTIC, CREATIVE, SATIRICAL, FICTIONAL ANALOGOUS
3 WORK OR PROGRAM, A MARKING OF HIGH–RISK ARTIFICIAL INTELLIGENCE
4 SYSTEMS UNDER PARAGRAPH (1) OF THIS SUBSECTION SHALL BE LIMITED IN A
5 MANNER NOT TO HINDER THE DISPLAY OR ENJOYMENT OF THE WORK OR PROGRAM.
6 (3) THE MARKING OF OUTPUTS REQUIRED UNDER PARAGRAPH (1) OF
7 THIS SUBSECTION DOES NOT APPLY TO:
8 (I) SYNTHETIC CONTENT THAT:
9 1. CONSISTS EXCLUSIVELY OF TEXT;
10 2. IS PUBLISHED TO INFORM THE PUBLIC ON ANY
11 MATTER OF PUBLIC INTEREST; OR
12 3. IS UNLIKELY TO MISLEAD A REASONABLE PERSON
13 CONSUMING THE SYNTHETIC CONTENT; OR
14 (II) THE OUTPUTS OF A HIGH–RISK ARTIFICIAL INTELLIGENCE
15 SYSTEM THAT:
16 1. PERFORMS AN ASSISTIVE FUNCTION FOR STANDARD
17 EDITING;
18 2. DOES NOT SUBSTANTIALLY ALTER THE INPUT DATA
19 PROVIDED BY THE DEVELOPER, OR IS USED TO DETECT, PREVENT, OR INVESTIGATE;
20 OR
21 3. PROSECUTES A CRIME AS AUTHORIZED BY LAW.
22 14–47A–04.
23 (A) (1) BEGINNING FEBRUARY 1, 2026, EACH DEPLOYER SHALL USE
24 REASONABLE CARE TO PROTECT CONSUMERS FROM ANY KNOWN OR REASONABLY
25 FORESEEABLE RISKS OF ALGORITHMIC DISCRIMINATION.
26 (2) IN AN ENFORCEMENT ACTION BROUGHT BY THE ATTORNEY
27 GENERAL UNDER THIS SUBTITLE, THERE SHALL BE A REBUTTABLE PRESUMPTION
28 THAT A DEPLOYER USED REASONABLE CARE AS REQUIRED UNDER THIS
29 SUBSECTION IF THE DEPLOYER COMPLIED WITH THE REQUIREMENTS OF THIS
30 SECTION.

14 SENATE BILL 936
1 (B) (1) BEGINNING FEBRUARY 1, 2026, AND SUBJECT TO PARAGRAPH (2)
2 OF THIS SUBSECTION, A DEPLOYER OF A HIGH–RISK ARTIFICIAL INTELLIGENCE
3 SYSTEM SHALL DESIGN, IMPLEMENT, AND MAINTAIN A RISK MANAGEMENT POLICY
4 AND PROGRAM FOR THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM.
5 (2) EACH RISK MANAGEMENT POLICY DESIGNED, IMPLEMENTED,
6 AND MAINTAINED IN ACCORDANCE WITH PARAGRAPH (1) OF THIS SUBSECTION
7 SHALL:
8 (I) SPECIFY THE PRINCIPLES, PROCESSES, AND PERSONNEL
9 THAT THE DEPLOYER USES TO IDENTIFY, MITIGATE, AND DOCUMENT ANY RISK OF
10 ALGORITHMIC DISCRIMINATION THAT IS A REASONABLY FORESEEABLE
11 CONSEQUENCE OF DEPLOYING OR USING THE HIGH–RISK ARTIFICIAL
12 INTELLIGENCE SYSTEM;
13 (II) BE REGULARLY REVIEWED AND UPDATED OVER THE LIFE
14 CYCLE OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM; AND
15 (III) BE REASONABLE AND IN CONSIDERATION OF THE
16 GUIDANCE AND STANDARDS PROVIDED IN THE LATEST VERSION OF:
17 1. THE ARTIFICIAL INTELLIGENCE RISK MANAGEMENT
18 FRAMEWORK PUBLISHED BY THE NATIONAL INSTITUTE OF STANDARDS AND
19 TECHNOLOGY;
20 2. STANDARD ISO/IEC 42001 OF THE INTERNATIONAL
21 ORGANIZATION FOR STANDARDIZATION;
22 3. ANOTHER NATIONALLY OR INTERNATIONALLY
23 RECOGNIZED RISK MANAGEMENT FRAMEWORK FOR ARTIFICIAL INTELLIGENCE
24 SYSTEMS WITH REQUIREMENTS THAT ARE SUBSTANTIALLY EQUIVALENT TO, AND AT
25 LEAST AS STRINGENT AS, THE REQUIREMENTS ESTABLISHED UNDER THIS SECTION;
26 OR
27 4. ANY RISK MANAGEMENT FRAMEWORK FOR
28 ARTIFICIAL INTELLIGENCE SYSTEMS THAT THE ATTORNEY GENERAL MAY
29 DESIGNATE AND IS SUBSTANTIALLY EQUIVALENT TO, AND AT LEAST AS STRINGENT
30 AS, THE GUIDANCE AND STANDARDS OF THE FRAMEWORK DESCRIBED IN ITEM 1 OF
31 THIS ITEM.
32 (3) A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM SHALL BE
33 PRESUMED TO SATISFY THE REQUIREMENTS UNDER THIS SECTION AND ANY
34 REGULATIONS ADOPTED IN ACCORDANCE WITH THIS SUBTITLE IF THE HIGH–RISK

SENATE BILL 936 15
1 ARTIFICIAL INTELLIGENCE SYSTEM IS IN CONFORMITY WITH THE LATEST VERSION
2 OF:
3 (I) THE ARTIFICIAL INTELLIGENCE RISK MANAGEMENT
4 FRAMEWORK PUBLISHED BY THE NATIONAL INSTITUTE OF STANDARDS AND
5 TECHNOLOGY;
6 (II) STANDARD ISO/IEC 42001 OF THE INTERNATIONAL
7 ORGANIZATION FOR STANDARDIZATION; OR
8 (III) ANOTHER NATIONALLY OR INTERNATIONALLY
9 RECOGNIZED RISK MANAGEMENT FRAMEWORK FOR ARTIFICIAL INTELLIGENCE
10 SYSTEMS THAT ARE SUBSTANTIALLY EQUIVALENT TO, AND AT LEAST AS STRINGENT
11 AS, THE REQUIREMENTS ESTABLISHED UNDER THIS SECTION.
12 (C) (1) SUBJECT TO PARAGRAPHS (2) AND (3) OF THIS SUBSECTION AND
13 EXCEPT AS PROVIDED IN PARAGRAPH (4) OF THIS SUBSECTION:
14 (I) ON OR AFTER FEBRUARY 1, 2026, BEFORE INITIAL
15 DEPLOYMENT OF A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM OR USE OF A
16 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, A DEPLOYER SHALL COMPLETE AN
17 IMPACT ASSESSMENT OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM; AND
18 (II) AT LEAST 90 DAYS BEFORE A SIGNIFICANT UPDATE TO A
19 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM IS MADE AVAILABLE, A DEPLOYER
20 SHALL COMPLETE AN IMPACT ASSESSMENT OF THE HIGH–RISK ARTIFICIAL
21 INTELLIGENCE SYSTEM IF THE UPDATE PRODUCES A NEW VERSION OR RELEASE OR
22 SIMILAR CHANGE TO THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM THAT:
23 1. INTRODUCES SIGNIFICANT CHANGES TO THE USE
24 CASE OR KEY FUNCTIONALITY OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE
25 SYSTEM; AND
26 2. RESULTS IN A NEW OR REASONABLY FORESEEABLE
27 RISK OF ALGORITHMIC DISCRIMINATION.
28 (2) EACH IMPACT ASSESSMENT COMPLETED UNDER PARAGRAPH (1)
29 OF THIS SUBSECTION SHALL INCLUDE:
30 (I) A STATEMENT BY THE DEPLOYER DISCLOSING THE
31 PURPOSE AND INTENDED USE CASES AND DEPLOYMENT CONTEXT OF, AND BENEFITS
32 AFFORDED BY, THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM;

16 SENATE BILL 936
1 (II) AN ANALYSIS OF WHETHER THE DEPLOYMENT OF THE
2 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM:
3 1. POSES ANY KNOWN OR REASONABLY FORESEEABLE
4 RISKS OF ALGORITHMIC DISCRIMINATION;
5 2. THE NATURE OF ANY ALGORITHMIC
6 DISCRIMINATION; AND
7 3. THE STEPS THAT HAVE BEEN TAKEN TO MITIGATE
8 RISKS;
9 (III) FOR A POSTDEPLOYMENT IMPACT ASSESSMENT
10 COMPLETED UNDER THIS SUBSECTION, AN ANALYSIS OF WHETHER THE INTENDED
11 USE CASES OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, AS UPDATED,
12 WERE CONSISTENT WITH, OR VARIED FROM, THE DEVELOPER’S INTENDED USES OF
13 THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM;
14 (IV) A DESCRIPTION OF THE CATEGORIES OF DATA THE
15 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM PROCESSES AS INPUTS AND THE
16 OUTPUTS THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM PRODUCES;
17 (V) IF THE DEPLOYER USED DATA TO CUSTOMIZE THE
18 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, AN OVERVIEW OF THE CATEGORIES
19 OF DATA THE DEPLOYER USED TO CUSTOMIZE THE HIGH–RISK ARTIFICIAL
20 INTELLIGENCE SYSTEM;
21 (VI) A LIST OF METRICS USED TO EVALUATE THE PERFORMANCE
22 AND KNOWN LIMITATIONS OF THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM;
23 (VII) A DESCRIPTION OF TRANSPARENCY MEASURES TAKEN
24 CONCERNING THE HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, INCLUDING ANY
25 MEASURES TAKEN TO DISCLOSE TO A CONSUMER THAT A HIGH–RISK ARTIFICIAL
26 INTELLIGENCE SYSTEM IS IN USE WHEN THE CONSUMER IS ENGAGING OR
27 INTERACTING WITH A SYSTEM OR PRODUCT IN WHICH A HIGH–RISK ARTIFICIAL
28 INTELLIGENCE SYSTEM IS IN USE;
29 (VIII) A DESCRIPTION OF POSTDEPLOYMENT MONITORING AND
30 USER SAFEGUARDS RELATED TO THE HIGH–RISK ARTIFICIAL INTELLIGENCE
31 SYSTEM, INCLUDING THE OVERSIGHT PROCESS ESTABLISHED BY THE DEPLOYER TO
32 ADDRESS ISSUES ARISING FROM DEPLOYMENT OR USE OF A HIGH–RISK ARTIFICIAL
33 INTELLIGENCE SYSTEM; AND

SENATE BILL 936 17
1 (IX) AN ANALYSIS OF THE VALIDITY AND RELIABILITY OF THE
2 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, IN ACCORDANCE WITH
3 CONTEMPORARY SOCIAL SCIENCE STANDARDS AND A DESCRIPTION OF METRICS TO
4 EVALUATE PERFORMANCE AND KNOWN LIMITATIONS OF THE HIGH–RISK
5 ARTIFICIAL INTELLIGENCE SYSTEM.
6 (3) A DEPLOYER SHALL MAINTAIN A COMPLETED IMPACT
7 ASSESSMENT OF A HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM REQUIRED
8 UNDER THIS SECTION AND ALL RECORDS CONCERNING THE IMPACT ASSESSMENT
9 FOR AT LEAST 3 YEARS.
10 (4) A SINGLE IMPACT ASSESSMENT MAY ADDRESS A COMPARABLE
11 SET OF HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEMS DEPLOYED BY A DEPLOYER.
12 (D) BEGINNING FEBRUARY 1, 2026, BEFORE A DEPLOYER DEPLOYS A
13 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM, THE DEPLOYER SHALL:
14 (1) NOTIFY THE CONSUMER THAT THE DEPLOYER HAS DEPLOYED A
15 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM TO MAKE, OR BE A SUBSTANTIAL
16 FACTOR IN MAKING, A CONSEQUENTIAL DECISION ABOUT THE CONSUMER; AND
17 (2) PROVIDE TO THE CONSUMER:
18 (I) A STATEMENT DISCLOSING THE PURPOSE OF THE
19 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM AND THE NATURE OF THE
20 CONSEQUENTIAL DECISION;
21 (II) IF APPLICABLE, INFORMATION CONCERNING THE
22 CONSUMER’S RIGHT TO OPT OUT OF THE PROCESSING OF THE CONSUMER’S
23 PERSONAL DATA IN ACCORDANCE WITH STATE OR FEDERAL LAW;
24 (III) CONTACT INFORMATION FOR THE DEPLOYER; AND
25 (IV) A DESCRIPTION, IN PLAIN LANGUAGE, OF THE HIGH–RISK
26 ARTIFICIAL INTELLIGENCE SYSTEM, INCLUDING:
27 1. THE PERSONAL CHARACTERISTICS OR ATTRIBUTES
28 THE ARTIFICIAL INTELLIGENCE SYSTEM WILL MEASURE OR ASSESS AND THE
29 METHOD BY WHICH THE SYSTEM MEASURES OR ASSESSES PERSONAL
30 CHARACTERISTICS OR ATTRIBUTES;

18 SENATE BILL 936
1 2. THE RELEVANCE OF PERSONAL CHARACTERISTICS
2 OR ATTRIBUTES TO CONSEQUENTIAL DECISIONS RELATED TO THE ARTIFICIAL
3 INTELLIGENCE SYSTEM;
4 3. ANY HUMAN COMPONENTS OF THE ARTIFICIAL
5 INTELLIGENCE SYSTEM;
6 4. THE MANNER IN WHICH AUTOMATED COMPONENTS
7 OF THE ARTIFICIAL INTELLIGENCE SYSTEM ARE USED TO INFORM CONSEQUENTIAL
8 DECISIONS RELATED TO THE SYSTEM; AND
9 5. A DIRECT LINK TO A PUBLICLY ACCESSIBLE WEBPAGE
10 ON THE DEPLOYER’S WEBSITE THAT CONTAINS A DESCRIPTION IN PLAIN LANGUAGE
11 OF THE LOGIC USED IN THE ARTIFICIAL INTELLIGENCE SYSTEM, INCLUDING:
12 A. KEY PARAMETERS THAT AFFECT THE OUTPUT OF THE
13 SYSTEM;
14 B. THE TYPE AND SOURCE OF DATA COLLECTED FROM
15 INDIVIDUALS AND PROCESSED BY THE SYSTEM IN MAKING OR ASSISTING IN MAKING
16 A CONSEQUENTIAL DECISION; AND
17 C. THE RESULTS OF THE MOST RECENT IMPACT
18 ASSESSMENT REQUIRED UNDER THIS SECTION.
19 (E) BEGINNING FEBRUARY 1, 2026, AND SUBJECT TO SUBSECTION (F) OF
20 THIS SECTION, A DEPLOYER THAT HAS DEPLOYED A HIGH–RISK ARTIFICIAL
21 INTELLIGENCE SYSTEM SHALL, IF A CONSEQUENTIAL DECISION IS ADVERSE TO THE
22 CONSUMER, PROVIDE TO THE CONSUMER:
23 (1) A STATEMENT DISCLOSING THE PRINCIPAL REASON OR REASONS
24 FOR THE ADVERSE CONSEQUENTIAL DECISION, INCLUDING:
25 (I) THE DEGREE TO WHICH, AND MANNER IN WHICH, THE
26 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM CONTRIBUTED TO THE ADVERSE
27 CONSEQUENTIAL DECISION;
28 (II) THE TYPE OF DATA THAT WERE PROCESSED BY THE
29 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM IN MAKING THE ADVERSE
30 CONSEQUENTIAL DECISION; AND
31 (III) THE SOURCE OF THE DATA DESCRIBED IN ITEM (II) OF THIS
32 ITEM; AND

SENATE BILL 936 19
1 (2) AN OPPORTUNITY TO:
2 (I) CORRECT ANY INCORRECT PERSONAL DATA THAT THE
3 HIGH–RISK ARTIFICIAL INTELLIGENCE SYSTEM PROCESSED IN MAKING, OR USED AS
4 A SUBSTANTIAL FACTOR IN MAKING, THE ADVERSE CONSEQUENTIAL DECISION; AND
5 (II) APPEAL THE ADVERSE CONSEQUENTIAL DECISION,
6 ALLOWING FOR HUMAN REVIEW UNLESS PROVIDING THIS OPPORTUNITY:
7 1. IS NOT IN THE BEST INTEREST OF THE CONSUMER; OR
8 2. MAY CAUSE A DELAY THAT POSES A RISK TO THE LIFE
9 OR SAFETY OF THE CONSUMER.
10 (F) THE DEPLOYER SHALL PROVIDE THE INFORMATION REQUIRED UNDER
11 SUBSECTION (E) OF THIS SUBSECTION:
12 (1) DIRECTLY TO THE CONSUMER;
13 (2) IN PLAIN LANGUAGE THAT IS TRANSLATED TO ANY LANGUAGES IN
14 WHICH THE DEPLOYER, IN THE ORDINARY COURSE OF SUCH DEPLOYER’S BUSINESS,
15 PROVIDES CONTRACTS, DISCLAIMERS, SALE ANNOUNCEMENTS, AND ANY OTHER
16 INFORMATION TO CONSUMERS; AND
17 (3) IN A FORMAT THAT IS ACCESSIBLE TO CONSUMERS WITH
18 DISABILITIES.
19 14–47A–05.
20 (A) THE REQUIREMENTS OF THIS SUBTITLE MAY NOT BE CONSTRUED TO
21 RESTRICT A DEVELOPER’S, A DEPLOYER’S, OR ANOTHER PERSON’S ABILITY TO:
22 (1) COMPLY WITH FEDERAL, STATE, OR LOCAL LAW;
23 (2) COMPLY WITH A CIVIL, CRIMINAL, OR REGULATORY INQUIRY, AN
24 INVESTIGATION, OR A SUBPOENA OR SUMMONS BY A FEDERAL, STATE, LOCAL, OR
25 OTHER GOVERNMENTAL AUTHORITY;
26 (3) COOPERATE WITH A LAW ENFORCEMENT AGENCY CONCERNING
27 CONDUCT OR ACTIVITY THAT THE DEVELOPER, DEPLOYER, OR OTHER PERSON
28 REASONABLY AND IN GOOD FAITH BELIEVES MAY VIOLATE FEDERAL, STATE, OR
29 LOCAL LAW;

20 SENATE BILL 936
1 (4) INVESTIGATE, ESTABLISH, EXERCISE, PREPARE FOR, OR DEFEND
2 A LEGAL CLAIM;
3 (5) TAKE IMMEDIATE STEPS TO PROTECT AN INTEREST THAT IS
4 ESSENTIAL FOR THE LIFE OR PHYSICAL SAFETY OF A CONSUMER OR ANOTHER
5 INDIVIDUAL;
6 (6) (I) BY ANY MEANS OTHER THAN FACIAL RECOGNITION
7 TECHNOLOGY, PREVENT, DETECT, PROTECT AGAINST, OR RESPOND TO:
8 1. A SECURITY INCIDENT;
9 2. A MALICIOUS OR DECEPTIVE ACTIVITY; OR
10 3. IDENTITY THEFT, FRAUD, HARASSMENT, OR ANY
11 OTHER ILLEGAL ACTIVITY;
12 (II) INVESTIGATE, REPORT, OR PROSECUTE THE PERSONS
13 RESPONSIBLE FOR ANY ACTION DESCRIBED IN ITEM (I) OF THIS ITEM; OR
14 (III) PRESERVE THE INTEGRITY OR SECURITY OF SYSTEMS;
15 (7) ENGAGE IN PUBLIC OR PEER–REVIEWED SCIENTIFIC OR
16 STATISTICAL RESEARCH IN THE PUBLIC INTEREST THAT:
17 (I) ADHERES TO ALL OTHER APPLICABLE ETHICS AND PRIVACY
18 LAWS; AND
19 (II) IS APPROVED, MONITORED, AND GOVERNED BY AN
20 INSTITUTIONAL REVIEW BOARD OR SIMILAR INDEPENDENT OVERSIGHT ENTITY
21 THAT DETERMINES:
22 1. WHETHER THE EXPECTED BENEFITS OF THE
23 RESEARCH OUTWEIGH THE RISKS ASSOCIATED WITH THE RESEARCH; AND
24 2. WHETHER THE DEVELOPER OR DEPLOYER HAS
25 IMPLEMENTED REASONABLE SAFEGUARDS TO MITIGATE THE RISKS ASSOCIATED
26 WITH THE RESEARCH;
27 (8) CONDUCT RESEARCH, TESTING, AND DEVELOPMENT ACTIVITIES
28 REGARDING AN ARTIFICIAL INTELLIGENCE SYSTEM OR MODEL, OTHER THAN
29 TESTING CONDUCTED UNDER REAL–WORLD CONDITIONS, BEFORE AN ARTIFICIAL

SENATE BILL 936 21
1 INTELLIGENCE SYSTEM OR MODEL IS PLACED ON THE MARKET, DEPLOYED OR PUT
2 INTO SERVICE, AS APPLICABLE;
3 (9) EFFECTUATE A PRODUCT RECALL;
4 (10) IDENTIFY AND REPAIR TECHNICAL ERRORS THAT IMPAIR
5 EXISTING OR INTENDED FUNCTIONALITY; OR
6 (11) ASSIST ANOTHER DEVELOPER, DEPLOYER, OR PERSON WITH ANY
7 OF THE OBLIGATIONS IMPOSED UNDER THIS SUBTITLE.
8 (B) THE OBLIGATIONS IMPOSED ON DEVELOPERS, DEPLOYERS, OR OTHER
9 PERSONS UNDER THIS SUBTITLE MAY NOT APPLY WHEN COMPLIANCE BY THE
10 DEVELOPER, DEPLOYER, OR OTHER PERSON WOULD VIOLATE AN EVIDENTIARY
11 PRIVILEGE UNDER THE LAWS OF THE STATE.
12 14–47A–06.
13 (A) A PERSON WHO VIOLATES THIS SUBTITLE IS SUBJECT TO A FINE NOT
14 EXCEEDING $1,000 AND, AS APPLICABLE, REASONABLE ATTORNEY’S FEES,
15 EXPENSES, AND COSTS, AS DETERMINED BY THE COURT.
16 (B) A PERSON WHO WILLFULLY VIOLATES THIS SUBTITLE IS SUBJECT TO A
17 FINE OF AT LEAST $1,000 AND NOT EXCEEDING $10,000 AND, AS APPLICABLE,
18 REASONABLE ATTORNEY’S FEES, EXPENSES, AND COSTS, AS DETERMINED BY THE
19 COURT.
20 (C) EACH VIOLATION OF THIS SUBTITLE IS A SEPARATE VIOLATION
21 SUBJECT TO THE CIVIL PENALTIES IMPOSED UNDER THIS SECTION.
22 14–47A–07.
23 (A) THE ATTORNEY GENERAL MAY ENFORCE THIS SUBTITLE.
24 (B) TO CARRY OUT THE REQUIREMENTS OF THIS SUBTITLE, THE ATTORNEY
25 GENERAL MAY:
26 (1) REQUIRE THAT A DEVELOPER DISCLOSE TO THE ATTORNEY
27 GENERAL:
28 (I) A STATEMENT OR DOCUMENTATION DESCRIBED IN THIS
29 SUBTITLE RELEVANT TO AN INVESTIGATION CONDUCTED BY THE ATTORNEY
30 GENERAL; AND

22 SENATE BILL 936
1 (II) A RISK MANAGEMENT POLICY DESIGNED AND
2 IMPLEMENTED, AN IMPACT ASSESSMENT COMPLETED, OR A RECORD MAINTAINED
3 UNDER THIS SUBTITLE RELEVANT TO AN INVESTIGATION CONDUCTED BY THE
4 ATTORNEY GENERAL;
5 (2) SUBJECT TO SUBSECTION (C) OF THIS SECTION, INITIATE A CIVIL
6 ACTION AGAINST A PERSON THAT VIOLATES THIS SUBTITLE; AND
7 (3) ADOPT REGULATIONS.
8 (C) (1) BEFORE BRINGING AN ACTION AGAINST A DEVELOPER OR
9 DEPLOYER FOR A VIOLATION OF THIS SUBTITLE, THE ATTORNEY GENERAL, IN
10 CONSULTATION WITH THE DEVELOPER OR DEPLOYER, SHALL DETERMINE IF IT IS
11 POSSIBLE TO CURE THE VIOLATION.
12 (2) IF IT IS POSSIBLE TO CURE THE VIOLATION, THE ATTORNEY
13 GENERAL MAY ISSUE A NOTICE OF VIOLATION TO THE DEVELOPER OR DEPLOYER
14 AND AFFORD THE DEVELOPER OR DEPLOYER THE OPPORTUNITY TO CURE THE
15 VIOLATION WITHIN 45 DAYS AFTER THE RECEIPT OF THE NOTICE OF VIOLATION.
16 (3) IN DETERMINING WHETHER TO GRANT A DEVELOPER OR
17 DEPLOYER AN OPPORTUNITY TO CURE A VIOLATION, THE ATTORNEY GENERAL
18 SHALL CONSIDER:
19 (I) THE NUMBER OF VIOLATIONS;
20 (II) THE SIZE AND COMPLEXITY OF THE DEVELOPER OR
21 DEPLOYER;
22 (III) THE NATURE AND EXTENT OF THE DEVELOPER’S OR
23 DEPLOYER’S BUSINESS;
24 (IV) WHETHER THERE IS A SUBSTANTIAL LIKELIHOOD OF
25 INJURY TO THE PUBLIC;
26 (V) THE SAFETY OF PERSONS OR PROPERTY; AND
27 (VI) WHETHER A VIOLATION WAS LIKELY CAUSED BY A HUMAN
28 OR TECHNICAL ERROR.
29 (4) IF A DEVELOPER OR DEPLOYER FAILS TO CURE A VIOLATION
30 WITHIN 45 DAYS AFTER THE RECEIPT OF A NOTICE OF VIOLATION UNDER

SENATE BILL 936 23
1 PARAGRAPH (3) OF THIS SUBSECTION, THE ATTORNEY GENERAL MAY PROCEED
2 WITH THE ACTION.
3 (D) IN AN ACTION BROUGHT BY THE ATTORNEY GENERAL UNDER THIS
4 SECTION, IT IS AN AFFIRMATIVE DEFENSE IF:
5 (1) A VIOLATION OF ANY PROVISION OF THIS SUBTITLE IS
6 DISCOVERED THROUGH RED–TEAMING, WHICH IS ADVERSARIAL TESTING
7 CONDUCTED FOR THE PURPOSE OF:
8 (I) IDENTIFYING THE POTENTIAL ADVERSE BEHAVIORS OR
9 OUTCOMES OF AN ARTIFICIAL INTELLIGENCE SYSTEM;
10 (II) IDENTIFYING HOW THE BEHAVIORS OR OUTCOMES OCCUR;
11 AND
12 (III) STRESS TESTING THE SAFEGUARDS AGAINST THE
13 BEHAVIORS OR OUTCOMES; AND
14 (2) NOT LATER THAN 45 DAYS AFTER DISCOVERING A VIOLATION
15 UNDER ITEM (1) OF THIS SUBSECTION, THE DEVELOPER OR DEPLOYER:
16 (I) CURES THE VIOLATION;
17 (II) PROVIDES NOTICE TO THE ATTORNEY GENERAL IN A FORM
18 AND MANNER PRESCRIBED BY THE ATTORNEY GENERAL THAT THE VIOLATION HAS
19 BEEN CURED AND EVIDENCE THAT ANY HARM CAUSED BY SUCH VIOLATION HAS
20 BEEN MITIGATED; AND
21 (III) IS OTHERWISE IN COMPLIANCE WITH THE REQUIREMENTS
22 OF THIS SUBTITLE.
23 14–47A–08.
24 A CONSUMER MAY BRING A CIVIL ACTION AGAINST A DEPLOYER IF:
25 (1) THE CONSUMER INITIALLY FILED A TIMELY ADMINISTRATIVE
26 CHARGE OR COMPLAINT UNDER FEDERAL, STATE, OR LOCAL LAW ALLEGING A
27 DISCRIMINATORY ACT BY THE DEPLOYER AS A RESULT OF A CONSEQUENTIAL
28 DECISION ABOUT THE CONSUMER THAT IS MADE BY A HIGH–RISK ARTIFICIAL
29 INTELLIGENCE SYSTEM OF THE DEPLOYER;

24 SENATE BILL 936
1 (2) AT LEAST 180 DAYS HAVE ELAPSED SINCE THE DATE OF FILING OF
2 THE ADMINISTRATIVE COMPLAINT; AND
3 (3) THE CIVIL ACTION IS FILED NOT MORE THAN 2 YEARS AFTER THE
4 OCCURRENCE OF THE ALLEGED DISCRIMINATORY ACT.
5 SECTION 2. AND BE IT FURTHER ENACTED, That, if any provision of this Act or
6 the application of any provision of this Act to any person or circumstance is held invalid for
7 any reason in a court of competent jurisdiction, the invalidity does not affect other
8 provisions or any other application of this Act that can be given effect without the invalid
9 provision or application, and for this purpose the provisions of this Act are declared
10 severable.
11 SECTION 3. AND BE IT FURTHER ENACTED, That this Act shall take effect
12 October 1, 2025.

[DELETED: :CA      5   C A C D F c h a i s t u r c t p c f k a r f r o c a d d p t t d o d r a d t m c d c m r a d t d i a m a r m u h a i s r a d t p c i h w a o t c c i a a a c c d a t A G t e t A a a c t b a c a a a d u c c s B  A S H  A  (  S T]
[DELETED:  S  A4.H–RAIDA.  IHI R N E C() N T S T F W H T M () ( “AL DN M T U O A O I T D A I O G O O T B O T ILS O GPS A O  () A;GE  () C;IO  () D;II  () E;VT  () G;E  () LE;II N  () N;IA  ()R;IA  () R;XE  () R;E  () S;IE  () S;IE  ()V;IES   ()CVL O P U TW]
[DELETED: S 3 ( “A”:N E  () T,,HR E HR DRS O DRS SFT T IY ME O’–, TW  () T,IH E O A AT A CR O A P T I D O R HN   () INC IICRA1442U.§20()   I I C      A() ( “A”R I SM M A MGB S T F A E O I OEST S S , ( “A I SM D N I ATG ()“C O DN M A D T H A L O S S E O T P OF ( P,,E N N  ( E;Y ( A; ( F;S ( A;S]
[DELETED:  S  ( H;G ( I; ( M;S  ( L.() ( “COR . ( “CR D N A I A I A() “D”ER  T O U A HHR A I S T M A T.() “D”ER  T O I A S M A HHRD D D N ,, T.() ( “G–”ELPL   () D;IY  () ISS   () IA B I I A V O D ( “G–LP A I ML D I A A I M T I U FT PG A R A B T() “GE A IE M ATO S T ,,.]
[DELETED: S 5() “GE A I SM M A() ( “H–IHR A I SM M A I S T I S I T ME O B A S F I MG A ( “H–HR A I SM D N  () NO   1 P;   2 Y   3 D A DNM P O ANMS ;   4 N   () T:IH   1  T T D N U   2 A IEE V G   3 A;   4 A;Y   5 C;S   6 C;Y   7 D;E]
[DELETED:  S    8 F;Y   9 I;N   1 I;G   1 N;G   1 S;G   1 S;   1 S;S   1 W;G   1 W;Y    1  T C WN M R O RS A A A I S T A A U P T P() ( “IN A S MN M A  () NN   () AI GLP A I M   1 A C O T GLP   2  C T P O TLPL ;   3  I A N R F]
[DELETED: S 7 ( “I A S MN D NHRM HRM ,:  () TH HHR A I SHRD D D D N ,,,R   () T:IH   1 I M T T HHR A I    2  P B T D O TR    3  A C W T I A O T HHR A I S  C 1().() ( “P”,EN M A IL A AN AE N Y P,,T E R E Y ,,. ( “P”.N () “P”RS HR ( H,,,W T T N ( M.() ( “SU FR M A F G B A  () H P B F M A CN ]
[DELETED:  S   () IA O A T O O A ( “SR T N N ,() “S”,YT N SS T O , B AS I B A A IT: ( E I A S W A HHR AE GG  U A A I S A B O F TT :  () TU.DC;H  E O  () TU.DD;IH  E EE   () TNAIH A E A P; ( A,R HR O D B A I F U I T B OE  NT1 A S T T P U I  O TE  ( A,,:R R   () IS A C E U T F EPAA1642U. O C C     010–, T D A T C F RS]
[DELETED: S 9  () P:IR   1  C R G B A I S I W A H C P I T T A T I T H CS    2  U A A IE L T Y,,() ( BF1,2,E E   A D O AHRN ( I A E A B B T TE  A D U R C A R U T I T D C W T P O T() BF1,2,(E E    D N HRR L E E R ,,,R HRM – ( AS D T I U O THR; ( D:G  () HHRM  F R O A D AHR;  () TIH P O T HHR AHRM]
[DELETED:  S   () I S D T M I W THR A I S W E FHRD D D N ,,,;  () VH K A F D O U O T HHRM   () TH M I W A I C U THRHR ( D:G  () TH M I W T HHR AE  D B T HHR A S W OD SD LD LD GN O,,,  () AI HL  () TIH I O O T HHR A  () VH K O R F R O AHRM ;  () TH M I W T HHR A S S B UD N UD A M B AD  (  A D T I R]
[DELETED: S 1  () UN T O O T HHRM   () MIO T P O T HHR() ( S()U S D O TN A DT  E   S S S S SF1,2,,,,, O M A T A D O O D AHR A I SM T T E PE, M A T D A O D T A I N F A D O T C B A D T C A I A  C E1(). (  D S M D A A A R U P  O T  () ARS I M C F T M A IYY ;  () D:IA   1  U T I U A H TT    2  I A P BA   () O.IT() ( FO A D R U T SN AR N L T  D A T D P A9 A S M T A HHR AM Y. ( AD T A S A A D F AHR A I S I N R T G D R U T S U T HHR I S I P T A U E]
[DELETED:  S () A HR S T A R U T S A AHR ( TAIR R N I ANI P B T A N O T A; ( SIC41   O T NS; TN  (  F F A I S T I E TO A A L A S AS TN() H ( T,§1 I A T ST A D I   O TE O O P F D U T OW  ( T:  () P;RR   () IE() ( AHR:  () RS   () C.IO]
[DELETED: S 1 ( F,O E C E L , O PM A M O HHR A I U P  O T S S B L I AM ( T(  O  () S:Y   1 C;   2  P T I T P O AT    3  U T M A R PT   () TIHHR   1    2 R T T E,,   3 P.() ( BF1,2E E   E D S UN ( I A E A B B T TE  A D U R C A R U T I T D C W T R O T]
[DELETED:  S () ( BF1,2,(E E     T SN A D O A HHR A IN T HRM. ( E, R M P DD ID M I A W P  O T S  () S,P T PS PS A PY E  D T I A R F O D O U T HHR A  () IEHRM ;  () IE R A I C O TF   1 TAIR R N I ANI P B T A N O T A;Y   2 SIC41    NS; T   3  N O I R M F F A IO S N   4  R M F F I S T T T E MO S    ( AHHR A I S S B T S T R U T S A AHR]
[DELETED: S 1  () TAIRH R N I ANI P B T A N O T A;  () SIC41IT   O T NS; TN   () IN N O I R M F F A IO S N.() ( S()(U      ):  () OF1,2N O A E   B I O A HHR A I S O U O AHRM HRM ;  () A9IT  D A S THRE  C A I A O T HHR AHR:   1  S C T T U O K F O T HHR A IM    2  N ( E(   ()  S B T D D TF Y HR–;]
[DELETED:  S   () IN A O W T D O THR:   1    2  N O A AN    3  S T H B T T M  () IO A P I AN HRM D,H M RS,HR;  () AV D O T C O D THR A I S P A I A THR;  () IF T D U D T C THRM  D T D U T C T HHR A  () I HR;  () I D O T M THRM HR S I I U W T C I E O W A S O P I W A HHR A  ()I D O P M A S R T T HHR A IM HRM ]
[DELETED: S 1  () XNHR A I SM I A W P A K L O T HHR ( D S M A C I O A HHR A I S R  . ( S I A M A A CHR.() BF1,2,E E   B A D D AHRM ,: ( HR A I S T ME O B A SG R ; ( P:  () A S D T P O THR A I S A T N O TN  () IIF AE I C TRS R T O O O T P O T CRS T;  () C;IOR   () A,,V N E HRM :   1  P C O A A I S W M O A A T B W T S M O A P]
[DELETED:  S    2  R O P C A T C D R T T A   3  H C O T A   4  M I W A CM    5 RSM :   A    B N    C  R O T M R IN() BF1,2,(E E    F  SN A D T H D A HHR AL R : ( N G:  () T,H D T WH A M I WH THR A I S C T T A  () TIH T O D T W P B THR A I S I M T AN   () T(IH II M ]
[DELETED: S 1 ( A:  () O A I P D T THRG G N ;  () AIP T A C DN   1 I;R    2 () H E ): ( D; ( R RSS’ CS DS S AS A A O,S  ()N A F T I A T C W() HRS RS NS,’,’: ( C,S,;L TE  ( C,,L L Y N L TE L ,S, (  O A T T DR DR O O P FL TE OS]
[DELETED:  S  ( I,,,E H E R  (  I S T P A I T I F T L O P S O A C O A ( () Y A M O T F RY T T T O,,,:   1 A;   2 A;Y    3 I,, TT FD HT O AY  () I,INE RT O P T P I M );  () P;IR ()EN I P O PRR S O  () DS   () I,IS AD MD A G B A R B O S I O E   1  T E B O TH    2  T D O D H R S T M T R A ( C,H G  A A I S O ML O TLWS ]
[DELETED: S 2T E ; ( E; (  A R T E T IY  ( A,R R () T,HS S  U T S M N A W C B TR DR O O P W V A E T.()    AD A AE R AYS FS0,,’S S T,.()   O A L  A N E  AD A AE0$0,YSS S S ,,T() A V O T S I A S VN() TAG.H T E() T,OE  T: ( R T A D D T T T:  ()  S O D D I T R T A I C B T T;L ]
[DELETED:  S   () I R M P D AD D  T S R T A I C B TG; E ( S() C N E  ( A.() ( E B A A A A D O F A V O T SE T T EL IAGR N ( I, I I P T C T VN T T A T D O D T O T C T  N5. (  D W T G A D O A O T C A VN T T EAR  () T;HS  () IH S A C O T D O  () TIH N A E O T DRS ORSS;  () VH T I A S L OC  () T;HY   () IHR (  A D O D F T C A V  D A T R O A N O V U]
[DELETED: S 2  O T SN T T E M P),AN() IAN A A B B T T E U TN : ( V O A P O T S I T RDTG W I A T  () D T P A B O  () IIDR  () IT T T S A TS  ( N4 L T  D A D A V  N R),:  () C;UN  () PAIR T E T E C A T A H C B S HD   () ISEA: (  C I F A T A O C U FL TE O L L A AS A B T D A A R O A C A T C T I M B A HHR A]
[DELETED:  S  ( A1  T  ( T  T  S t a r i a c o c j t i d n a o p p o a a f t p t p o t A a d s  S A B I F E T t A s t e O]